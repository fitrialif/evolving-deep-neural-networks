{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import preprocessing\n",
    "from keras import backend as K\n",
    "from math import pi, floor\n",
    "import random\n",
    "from codeepneat import codeepneat, config, population, chromosome, genome, visualize\n",
    "import pickle\n",
    "import numpy as np\n",
    "import keras\n",
    "import collections\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 5101618\n"
     ]
    }
   ],
   "source": [
    "path = keras.utils.get_file(\n",
    "    'ptb.train.txt',\n",
    "    origin='https://raw.githubusercontent.com/wojzaremba/lstm/master/data/ptb.train.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 5101618\n"
     ]
    }
   ],
   "source": [
    "path = keras.utils.get_file(\n",
    "    'ptb.valid.txt',\n",
    "    origin='https://github.com/wojzaremba/lstm/blob/master/data/ptb.valid.txt')\n",
    "text_val = open(path).read().lower()\n",
    "print('Corpus length:', len(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 2550759\n",
      "Unique characters: 49\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 100\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 2\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x_train = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y_train = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_train[i, t, char_indices[char]] = 1\n",
    "    y_train[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 2550759\n",
      "Unique characters: 49\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 100\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 2\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars_val = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices_val = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x_val = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y_val = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_val[i, t, char_indices[char]] = 1\n",
    "    y_val[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [x_train[0:100], y_train[0:100], x_val[0:100], y_val[0:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting configReuters\n"
     ]
    }
   ],
   "source": [
    "%%file configReuters\n",
    "#--- parameters for the robot experiment ---#\n",
    "[phenotype]\n",
    "input_nodes         = 100, 49\n",
    "output_nodes        = 49\n",
    "conv                = False\n",
    "LSTM                = True\n",
    "\n",
    "[genetic]\n",
    "max_fitness_threshold = 1\n",
    "\n",
    "# Human reasoning\n",
    "pop_size              = 10\n",
    "prob_addconv          = 0.0\n",
    "prob_addLSTM          = 1\n",
    "prob_addlayer         = 0.1\n",
    "prob_mutatelayer      = 0.4\n",
    "prob_addmodule        = 0.05\n",
    "prob_switchmodule     = 0.3\n",
    "elitism               = 1\n",
    "\n",
    "[genotype compatibility]\n",
    "compatibility_threshold = 3.0\n",
    "compatibility_change    = 0.0\n",
    "excess_coefficient      = 5.0\n",
    "disjoint_coefficient    = 3.0\n",
    "connection_coefficient  = 0.4\n",
    "size_coefficient        = 0.8\n",
    "\n",
    "[species]\n",
    "species_size        = 10\n",
    "survival_threshold  = 0.2\n",
    "old_threshold       = 30\n",
    "youth_threshold     = 10\n",
    "old_penalty         = 0.2\n",
    "youth_boost         = 1.2\n",
    "max_stagnation      = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(network, data):\n",
    "    K.set_learning_phase(1)\n",
    "    network.fit(data[0], data[1],  epochs=5, batch_size = 128)\n",
    "    K.set_learning_phase(0)\n",
    "    start_index = random.randint(0, 2550658)\n",
    "    generated_text = text_val[start_index: start_index + 100]\n",
    "    for i in range(400):\n",
    "        sampled = np.zeros((1, 100, 49))\n",
    "        for t, char in enumerate(generated_text):\n",
    "            sampled[0, t, char_indices_val[char]] = 1.\n",
    "\n",
    "        preds = network.predict(sampled, verbose=0)[0]\n",
    "        next_index = sample(preds, 0.2)\n",
    "        next_char = chars_val[next_index]\n",
    "\n",
    "        generated_text += next_char\n",
    "        generated_text = generated_text[1:]\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "        \n",
    " \n",
    "    #return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve(n, debugging=False):\n",
    "    if(debugging):\n",
    "        debug = open(\"debug.txt\", \"w\")\n",
    "    else:\n",
    "        debug = None\n",
    "    config.load('configReuters')\n",
    "    # Create 2 separate populations (size is now defined explicitly, but config file can still be used)\n",
    "    module_pop = population.Population(15, chromosome.ModuleChromo, debug=debug)\n",
    "    # As the top hierarchical level, the blueprint population needs to be able to see the module population\n",
    "    blueprint_pop = population.Population(10, chromosome.BlueprintChromo, module_pop, debug=debug)\n",
    "    # Most of the actual evolving is now handled outside of the population, by CoDeepNEAT\n",
    "    # Instead of requiring the user to overwrite the evaluation function, CoDeepNEAT evaluates the populations itself,\n",
    "    # it simply requires a fitness function for the networks it creates passed in as an argument.\n",
    "    codeepneat.epoch(n, blueprint_pop, module_pop, 2, fitness, data, save_best=True, name='reuters', debug=debug)\n",
    "    # It will still stop if fitness surpasses the max_fitness_threshold in config file\n",
    "    # Plots the evolution of the best/average fitness\n",
    "    visualize.plot_stats(module_pop.stats, name=\"ptbmod_\")\n",
    "    visualize.plot_stats(blueprint_pop.stats, name=\"bp_\")\n",
    "    # Visualizes speciation\n",
    "    #visualize.plot_species(module_pop.species_log, name=\"NMISTmod_\")\n",
    "    #visualize.plot_species(blueprint_pop.species_log, name=\"NMISTbp_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Generation 0--------\n",
      "Network 0\n",
      "Epoch 1/5\n",
      "100/100 [==============================] - 1s - loss: 3.8906 - acc: 0.0500\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s - loss: 3.7996 - acc: 0.2100\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s - loss: 3.2858 - acc: 0.2100\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s - loss: 3.7219 - acc: 0.0900\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s - loss: 3.2882 - acc: 0.0900\n",
      "r                               r  r   r       r   r   rr   r       r         r    rr           r         r            r                      r  rr    rr r    c    r r           r    r  r       r      r    r r   r  r                        r       r       r    r    r                   rr      r r        r        r   r r      r           r rr   r   r r   r   r r              r r         r        r \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5e139d51a69e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-91c33f18f4f9>\u001b[0m in \u001b[0;36mevolve\u001b[0;34m(n, debugging)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Instead of requiring the user to overwrite the evaluation function, CoDeepNEAT evaluates the populations itself,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# it simply requires a fitness function for the networks it creates passed in as an argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mcodeepneat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblueprint_pop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_pop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reuters'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m# It will still stop if fitness surpasses the max_fitness_threshold in config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Plots the evolution of the best/average fitness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs81/project-huppili1-zzhao1/experiment/CDNEAT/codeepneat/codeepneat.py\u001b[0m in \u001b[0;36mepoch\u001b[0;34m(n, pop1, pop2, num_networks, f, data, save_best, name, report, debug)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ERROR\\n'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_populations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbp_pop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_pop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs81/project-huppili1-zzhao1/experiment/CDNEAT/codeepneat/codeepneat.py\u001b[0m in \u001b[0;36mepoch\u001b[0;34m(n, pop1, pop2, num_networks, f, data, save_best, name, report, debug)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mprint_populations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpop2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_networks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----Modules-----------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpop2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs81/project-huppili1-zzhao1/experiment/CDNEAT/codeepneat/codeepneat.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(blueprint_pop, module_pop, num_networks, f, data, debug)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Get fitness of created network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mavg_fit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Network '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' Fitness: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "evolve(25, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
