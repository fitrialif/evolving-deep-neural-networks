{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from devol import DEvol, GenomeHandler\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset\n",
    "This problem uses mnist, a handwritten digit classification problem used for many introductory deep learning examples. Here, we load the data and prepare it for use by the GPU. We also do a one-hot encoding of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shapes\n",
      "  x train: (50000, 32, 32, 3)\n",
      "  x test: (10000, 32, 32, 3)\n",
      "  y train: (50000,)\n",
      "  y test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "K.set_image_data_format(\"channels_last\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = y_train[:,0]\n",
    "y_test = y_test[:,0]\n",
    "print(\"data shapes\")\n",
    "print(\"  x train:\", x_train.shape)\n",
    "print(\"  x test:\", x_test.shape)\n",
    "print(\"  y train:\", y_train.shape)\n",
    "print(\"  y test:\", y_test.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3).astype('float32') / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3).astype('float32') / 255\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "dataset = ((x_train, y_train), (x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the genome configuration\n",
    "The `GenomeHandler` class handles the constraints that are imposed upon models in a particular genetic program. In this example, a genome is allowed **up to** 3 convolutional layeres, 2 dense layers, 64 feature maps in each convolution, and 1024 nodes in each dense layer. It also specifies two possible activation functions(relu and sigmoid). See `genome-handler.py` for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "max_conv_layers = 5\n",
    "max_dense_layers = 2 # including final softmax layer\n",
    "max_conv_kernels = 64\n",
    "max_dense_nodes = 1024\n",
    "input_shape = x_train.shape[1:]\n",
    "num_classes = 10\n",
    "#activ = [\"sigmoid\"]  # using sigmoid as activation only\n",
    "activ = [\"relu\"]   # using relu as activation only\n",
    "#activ = None # using both sigmoid and relu\n",
    "\n",
    "genome_handler = GenomeHandler(max_conv_layers, max_dense_layers, max_conv_kernels, \\\n",
    "                    max_dense_nodes, input_shape, num_classes, \\\n",
    "                    batch_normalization=True, dropout=True, max_pooling=True, \\\n",
    "                optimizers=None, activations=activ)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and run the genetic program\n",
    "The next, and final, step is create a `DEvol` and run it. Here we specify a few settings pertaining to the genetic program. In this example, we have 10 generations of evolution, 10 members in each population, and 3 epochs of training used to evaluate each model's fitness. The program will save each genome's encoding, as well as the model's loss and accuracy, in a `.csv` file printed at the beginning of program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genome encoding and accuracy data stored at Thu Nov  9 23:50:33 2017.csv \n",
      "\n",
      "\n",
      "model 1/10 - generation 1/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.6140 - acc: 0.4148 - val_loss: 1.6017 - val_acc: 0.4289\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.3184 - acc: 0.5272 - val_loss: 1.8344 - val_acc: 0.3627\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.2125 - acc: 0.5673 - val_loss: 1.3706 - val_acc: 0.5176\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 38s - loss: 1.1358 - acc: 0.5976 - val_loss: 1.6489 - val_acc: 0.4112\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 41s - loss: 1.0755 - acc: 0.6227 - val_loss: 1.2607 - val_acc: 0.5602\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.0319 - acc: 0.6360 - val_loss: 1.3438 - val_acc: 0.5111\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.0026 - acc: 0.6471 - val_loss: 1.2415 - val_acc: 0.5776\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 38s - loss: 0.9757 - acc: 0.6596 - val_loss: 1.1716 - val_acc: 0.5866\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 41s - loss: 0.9523 - acc: 0.6669 - val_loss: 1.0873 - val_acc: 0.6344\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 39s - loss: 0.9356 - acc: 0.6748 - val_loss: 1.2398 - val_acc: 0.5590\n",
      "\n",
      "model 2/10 - generation 1/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 34s - loss: 1.4952 - acc: 0.4762 - val_loss: 1.5007 - val_acc: 0.4791\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.1011 - acc: 0.6113 - val_loss: 1.1304 - val_acc: 0.5940\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 35s - loss: 0.9580 - acc: 0.6685 - val_loss: 1.0236 - val_acc: 0.6380\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 36s - loss: 0.8837 - acc: 0.6958 - val_loss: 0.9809 - val_acc: 0.6531\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 37s - loss: 0.8301 - acc: 0.7144 - val_loss: 1.1881 - val_acc: 0.6064\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 39s - loss: 0.7952 - acc: 0.7274 - val_loss: 0.9420 - val_acc: 0.6775\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 34s - loss: 0.7691 - acc: 0.7364 - val_loss: 0.9297 - val_acc: 0.6835\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 36s - loss: 0.7490 - acc: 0.7438 - val_loss: 0.9315 - val_acc: 0.6737\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 34s - loss: 0.7264 - acc: 0.7514 - val_loss: 1.1027 - val_acc: 0.6407\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 3/10 - generation 1/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 51s - loss: 1.4625 - acc: 0.4895 - val_loss: 1.5302 - val_acc: 0.4574\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 53s - loss: 1.1618 - acc: 0.5972 - val_loss: 1.3522 - val_acc: 0.5332\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 45s - loss: 1.0564 - acc: 0.6373 - val_loss: 1.4356 - val_acc: 0.4877\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 52s - loss: 0.9898 - acc: 0.6609 - val_loss: 1.1986 - val_acc: 0.5830\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 50s - loss: 0.9348 - acc: 0.6804 - val_loss: 1.1744 - val_acc: 0.5811\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 52s - loss: 0.8997 - acc: 0.6922 - val_loss: 1.1975 - val_acc: 0.5780\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 47s - loss: 0.8512 - acc: 0.7103 - val_loss: 1.3692 - val_acc: 0.5177\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 4/10 - generation 1/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 51s - loss: 1.6965 - acc: 0.3941 - val_loss: 1.6266 - val_acc: 0.4257\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 47s - loss: 1.3061 - acc: 0.5272 - val_loss: 1.3702 - val_acc: 0.5134\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 47s - loss: 1.1569 - acc: 0.5879 - val_loss: 1.1710 - val_acc: 0.6141\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 49s - loss: 1.0588 - acc: 0.6255 - val_loss: 1.0190 - val_acc: 0.6611\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 49s - loss: 0.9815 - acc: 0.6532 - val_loss: 1.0219 - val_acc: 0.6721\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 50s - loss: 0.9200 - acc: 0.6737 - val_loss: 1.4364 - val_acc: 0.5075\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "model 5/10 - generation 1/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 33s - loss: 1.6395 - acc: 0.4185 - val_loss: 1.4796 - val_acc: 0.4757\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 33s - loss: 1.4507 - acc: 0.4875 - val_loss: 1.4384 - val_acc: 0.4843\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 31s - loss: 1.3827 - acc: 0.5146 - val_loss: 1.3520 - val_acc: 0.5196\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 32s - loss: 1.3394 - acc: 0.5304 - val_loss: 1.3344 - val_acc: 0.5259\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 29s - loss: 1.3164 - acc: 0.5407 - val_loss: 1.3092 - val_acc: 0.5372\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 35s - loss: 1.2929 - acc: 0.5475 - val_loss: 1.2901 - val_acc: 0.5503\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 34s - loss: 1.2752 - acc: 0.5545 - val_loss: 1.2838 - val_acc: 0.5483\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 36s - loss: 1.2653 - acc: 0.5573 - val_loss: 1.2790 - val_acc: 0.5543\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 35s - loss: 1.2496 - acc: 0.5650 - val_loss: 1.2762 - val_acc: 0.5495\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.2403 - acc: 0.5692 - val_loss: 1.2551 - val_acc: 0.5629\n",
      "\n",
      "model 6/10 - generation 1/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.5268 - acc: 0.4529 - val_loss: 1.4517 - val_acc: 0.4826\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 38s - loss: 1.2873 - acc: 0.5407 - val_loss: 1.1856 - val_acc: 0.5700\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.2049 - acc: 0.5718 - val_loss: 1.1350 - val_acc: 0.5916\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.1585 - acc: 0.5880 - val_loss: 1.0925 - val_acc: 0.6108\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.1219 - acc: 0.6020 - val_loss: 1.2030 - val_acc: 0.5762\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.0869 - acc: 0.6158 - val_loss: 1.0724 - val_acc: 0.6122\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.0658 - acc: 0.6229 - val_loss: 1.0307 - val_acc: 0.6371\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.0420 - acc: 0.6336 - val_loss: 1.0932 - val_acc: 0.6135\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.0301 - acc: 0.6367 - val_loss: 1.0592 - val_acc: 0.6267\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 7/10 - generation 1/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 51s - loss: 1.6478 - acc: 0.4135 - val_loss: 2.8912 - val_acc: 0.1859\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 49s - loss: 1.3379 - acc: 0.5185 - val_loss: 2.7136 - val_acc: 0.2081\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 50s - loss: 1.2369 - acc: 0.5574 - val_loss: 3.1605 - val_acc: 0.1579\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 49s - loss: 1.1692 - acc: 0.5842 - val_loss: 3.1813 - val_acc: 0.1632\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "model 8/10 - generation 1/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 35s - loss: 1.7260 - acc: 0.3914 - val_loss: 1.8745 - val_acc: 0.3566\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 34s - loss: 1.5106 - acc: 0.4755 - val_loss: 1.7469 - val_acc: 0.3897\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 37s - loss: 1.4338 - acc: 0.5018 - val_loss: 1.5735 - val_acc: 0.4653\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 37s - loss: 1.3956 - acc: 0.5176 - val_loss: 1.5480 - val_acc: 0.4671\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 35s - loss: 1.3732 - acc: 0.5268 - val_loss: 1.5517 - val_acc: 0.4661\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 37s - loss: 1.3673 - acc: 0.5316 - val_loss: 1.5554 - val_acc: 0.4889\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "model 9/10 - generation 1/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 61s - loss: 1.4769 - acc: 0.4918 - val_loss: 3.6040 - val_acc: 0.3362\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 62s - loss: 1.0965 - acc: 0.6190 - val_loss: 1.1394 - val_acc: 0.6173\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 59s - loss: 0.9539 - acc: 0.6750 - val_loss: 1.0643 - val_acc: 0.6413\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 61s - loss: 0.8611 - acc: 0.7119 - val_loss: 1.1502 - val_acc: 0.6631\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 59s - loss: 0.7753 - acc: 0.7459 - val_loss: 0.9944 - val_acc: 0.6710\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 59s - loss: 0.7147 - acc: 0.7673 - val_loss: 1.4208 - val_acc: 0.6795\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 59s - loss: 0.6627 - acc: 0.7890 - val_loss: 1.1990 - val_acc: 0.6770\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 10/10 - generation 1/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 43s - loss: 14.4982 - acc: 0.1000 - val_loss: 13.8688 - val_acc: 0.1000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 41s - loss: 14.5063 - acc: 0.1000 - val_loss: 13.8713 - val_acc: 0.1000\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 41s - loss: 14.5063 - acc: 0.1000 - val_loss: 13.8707 - val_acc: 0.1000\n",
      "Epoch 00002: early stopping\n",
      "Generation 1:\t\tbest accuracy: 0.6770\t\taverage: 0.4844\t\tstd: 0.1860\n",
      "\n",
      "model 1/10 - generation 2/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 30s - loss: 1.7824 - acc: 0.3512 - val_loss: 1.6438 - val_acc: 0.4041\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 31s - loss: 1.5703 - acc: 0.4315 - val_loss: 1.4839 - val_acc: 0.4635\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 31s - loss: 1.4022 - acc: 0.4994 - val_loss: 1.3703 - val_acc: 0.5161\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 33s - loss: 1.2523 - acc: 0.5601 - val_loss: 1.2755 - val_acc: 0.5493\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 33s - loss: 1.1569 - acc: 0.5971 - val_loss: 1.2578 - val_acc: 0.5549\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 30s - loss: 1.0919 - acc: 0.6204 - val_loss: 1.2550 - val_acc: 0.5596\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 32s - loss: 1.0330 - acc: 0.6393 - val_loss: 1.2320 - val_acc: 0.5648\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 31s - loss: 0.9632 - acc: 0.6670 - val_loss: 1.2211 - val_acc: 0.5792\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 31s - loss: 0.9096 - acc: 0.6842 - val_loss: 1.1827 - val_acc: 0.5931\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 31s - loss: 0.8719 - acc: 0.6983 - val_loss: 1.2227 - val_acc: 0.5906\n",
      "\n",
      "model 2/10 - generation 2/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 45s - loss: 1.8129 - acc: 0.3361 - val_loss: 1.5701 - val_acc: 0.4356\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 45s - loss: 1.5985 - acc: 0.4034 - val_loss: 1.6048 - val_acc: 0.4649\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 45s - loss: 1.5368 - acc: 0.4322 - val_loss: 1.7969 - val_acc: 0.3528\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "model 3/10 - generation 2/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 27s - loss: 1.6531 - acc: 0.4130 - val_loss: 1.4166 - val_acc: 0.4986\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 25s - loss: 1.3870 - acc: 0.5100 - val_loss: 1.4278 - val_acc: 0.4958\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 24s - loss: 1.3077 - acc: 0.5393 - val_loss: 1.3871 - val_acc: 0.5132\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 26s - loss: 1.2582 - acc: 0.5570 - val_loss: 1.3155 - val_acc: 0.5404\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 25s - loss: 1.2270 - acc: 0.5706 - val_loss: 1.2934 - val_acc: 0.5485\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 27s - loss: 1.2028 - acc: 0.5797 - val_loss: 1.2126 - val_acc: 0.5733\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 26s - loss: 1.1805 - acc: 0.5899 - val_loss: 1.2162 - val_acc: 0.5737\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 26s - loss: 1.1609 - acc: 0.5957 - val_loss: 1.2208 - val_acc: 0.5705\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 4/10 - generation 2/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 41s - loss: 1.5156 - acc: 0.4561 - val_loss: 1.4108 - val_acc: 0.4977\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.2978 - acc: 0.5359 - val_loss: 1.2996 - val_acc: 0.5395\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.2220 - acc: 0.5671 - val_loss: 1.3106 - val_acc: 0.5312\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.1730 - acc: 0.5815 - val_loss: 1.2415 - val_acc: 0.5616\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 41s - loss: 1.1316 - acc: 0.5986 - val_loss: 1.1097 - val_acc: 0.6029\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 40s - loss: 1.1005 - acc: 0.6104 - val_loss: 1.2958 - val_acc: 0.5434\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 38s - loss: 1.0781 - acc: 0.6177 - val_loss: 1.0744 - val_acc: 0.6130\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.0540 - acc: 0.6276 - val_loss: 1.2169 - val_acc: 0.5704\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 39s - loss: 1.0371 - acc: 0.6304 - val_loss: 1.0543 - val_acc: 0.6229\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 40s - loss: 1.0197 - acc: 0.6411 - val_loss: 0.9820 - val_acc: 0.6528\n",
      "\n",
      "model 5/10 - generation 2/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.5930 - acc: 0.4218 - val_loss: 1.5576 - val_acc: 0.4976\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 9s - loss: 1.2828 - acc: 0.5410 - val_loss: 1.8487 - val_acc: 0.3843\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 9s - loss: 1.1602 - acc: 0.5876 - val_loss: 2.8998 - val_acc: 0.2258\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "model 6/10 - generation 2/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 27s - loss: 1.8555 - acc: 0.3507 - val_loss: 2.0783 - val_acc: 0.2516\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 27s - loss: 1.4938 - acc: 0.4647 - val_loss: 1.9683 - val_acc: 0.2797\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 27s - loss: 1.3320 - acc: 0.5228 - val_loss: 2.3643 - val_acc: 0.2084\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 27s - loss: 1.2378 - acc: 0.5593 - val_loss: 2.1442 - val_acc: 0.2483\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "model 7/10 - generation 2/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.5418 - acc: 0.4632 - val_loss: 1.6937 - val_acc: 0.4199\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2250 - acc: 0.5733 - val_loss: 2.0315 - val_acc: 0.3471\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1201 - acc: 0.6126 - val_loss: 1.1558 - val_acc: 0.6055\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0602 - acc: 0.6337 - val_loss: 1.3885 - val_acc: 0.5266\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 15s - loss: 1.0116 - acc: 0.6523 - val_loss: 1.6289 - val_acc: 0.4483\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "model 8/10 - generation 2/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.5979 - acc: 0.4316 - val_loss: 1.3369 - val_acc: 0.5238\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1984 - acc: 0.5710 - val_loss: 1.1289 - val_acc: 0.6029\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0488 - acc: 0.6278 - val_loss: 1.2166 - val_acc: 0.5636\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9489 - acc: 0.6639 - val_loss: 0.9432 - val_acc: 0.6781\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8744 - acc: 0.6941 - val_loss: 0.9104 - val_acc: 0.6888\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8174 - acc: 0.7115 - val_loss: 0.8858 - val_acc: 0.7012\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.7608 - acc: 0.7338 - val_loss: 0.9689 - val_acc: 0.6619\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.7152 - acc: 0.7501 - val_loss: 1.0246 - val_acc: 0.6410\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 9/10 - generation 2/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 26s - loss: 1.6980 - acc: 0.4102 - val_loss: 1.5494 - val_acc: 0.4744\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 25s - loss: 1.3298 - acc: 0.5322 - val_loss: 1.3859 - val_acc: 0.5079\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 25s - loss: 1.2333 - acc: 0.5690 - val_loss: 1.7909 - val_acc: 0.4379\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 25s - loss: 1.1720 - acc: 0.5952 - val_loss: 1.4652 - val_acc: 0.5175\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "model 10/10 - generation 2/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 10s - loss: 1.5687 - acc: 0.4339 - val_loss: 1.7118 - val_acc: 0.4042\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 9s - loss: 1.2732 - acc: 0.5483 - val_loss: 1.2905 - val_acc: 0.5487\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 9s - loss: 1.1550 - acc: 0.5910 - val_loss: 1.3287 - val_acc: 0.5318\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 10s - loss: 1.0939 - acc: 0.6136 - val_loss: 1.5291 - val_acc: 0.4397\n",
      "Epoch 00003: early stopping\n",
      "Generation 2:\t\tbest accuracy: 0.6528\t\taverage: 0.4687\t\tstd: 0.1461\n",
      "\n",
      "model 1/10 - generation 3/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.6066 - acc: 0.4321 - val_loss: 1.3909 - val_acc: 0.5097\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2763 - acc: 0.5484 - val_loss: 1.2250 - val_acc: 0.5675\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1628 - acc: 0.5934 - val_loss: 1.1716 - val_acc: 0.5935\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0802 - acc: 0.6230 - val_loss: 1.1661 - val_acc: 0.5978\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0282 - acc: 0.6421 - val_loss: 1.1075 - val_acc: 0.6114\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9796 - acc: 0.6581 - val_loss: 1.0829 - val_acc: 0.6246\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9475 - acc: 0.6711 - val_loss: 1.0817 - val_acc: 0.6253\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9223 - acc: 0.6793 - val_loss: 1.0686 - val_acc: 0.6285\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8985 - acc: 0.6891 - val_loss: 1.0509 - val_acc: 0.6373\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8758 - acc: 0.6950 - val_loss: 1.0611 - val_acc: 0.6350\n",
      "\n",
      "model 2/10 - generation 3/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.5923 - acc: 0.4363 - val_loss: 1.6933 - val_acc: 0.4068\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.3672 - acc: 0.5256 - val_loss: 1.4363 - val_acc: 0.5099\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.2932 - acc: 0.5528 - val_loss: 1.6152 - val_acc: 0.4466\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.2427 - acc: 0.5726 - val_loss: 1.5135 - val_acc: 0.4820\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "model 3/10 - generation 3/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.6492 - acc: 0.4114 - val_loss: 1.7468 - val_acc: 0.4081\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.3883 - acc: 0.5094 - val_loss: 1.5932 - val_acc: 0.4556\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3175 - acc: 0.5402 - val_loss: 1.3664 - val_acc: 0.5210\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2657 - acc: 0.5595 - val_loss: 1.4684 - val_acc: 0.5248\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2308 - acc: 0.5755 - val_loss: 1.1438 - val_acc: 0.6131\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2037 - acc: 0.5836 - val_loss: 1.1653 - val_acc: 0.6011\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1809 - acc: 0.5938 - val_loss: 1.3609 - val_acc: 0.5586\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 4/10 - generation 3/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 10s - loss: 1.6216 - acc: 0.4286 - val_loss: 1.8455 - val_acc: 0.3784\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 9s - loss: 1.2956 - acc: 0.5400 - val_loss: 1.6941 - val_acc: 0.4213\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 9s - loss: 1.1931 - acc: 0.5774 - val_loss: 1.6878 - val_acc: 0.4421\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 9s - loss: 1.1283 - acc: 0.6026 - val_loss: 1.3226 - val_acc: 0.5271\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 9s - loss: 1.0883 - acc: 0.6173 - val_loss: 2.3034 - val_acc: 0.3373\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 9s - loss: 1.0556 - acc: 0.6319 - val_loss: 1.5509 - val_acc: 0.4593\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "model 5/10 - generation 3/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.7618 - acc: 0.3648 - val_loss: 1.5195 - val_acc: 0.4449\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.5413 - acc: 0.4474 - val_loss: 1.7326 - val_acc: 0.3862\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.4897 - acc: 0.4686 - val_loss: 1.4051 - val_acc: 0.4937\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.4529 - acc: 0.4845 - val_loss: 1.4539 - val_acc: 0.4738\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.4259 - acc: 0.4911 - val_loss: 1.4804 - val_acc: 0.4915\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "model 6/10 - generation 3/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6216 - acc: 0.4196 - val_loss: 1.8513 - val_acc: 0.3485\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.2457 - acc: 0.5522 - val_loss: 1.4831 - val_acc: 0.4776\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.0997 - acc: 0.6082 - val_loss: 1.2456 - val_acc: 0.5807\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0012 - acc: 0.6477 - val_loss: 1.4402 - val_acc: 0.4863\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9233 - acc: 0.6758 - val_loss: 1.0836 - val_acc: 0.6265\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.8549 - acc: 0.6995 - val_loss: 0.9495 - val_acc: 0.6880\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.8004 - acc: 0.7200 - val_loss: 1.0188 - val_acc: 0.6452\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.7558 - acc: 0.7349 - val_loss: 0.9018 - val_acc: 0.6877\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.7180 - acc: 0.7475 - val_loss: 1.0778 - val_acc: 0.6211\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.6783 - acc: 0.7632 - val_loss: 0.8287 - val_acc: 0.7187\n",
      "\n",
      "model 7/10 - generation 3/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.8067 - acc: 0.3329 - val_loss: 1.6431 - val_acc: 0.4109\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.5649 - acc: 0.4181 - val_loss: 1.3941 - val_acc: 0.5285\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.4913 - acc: 0.4495 - val_loss: 1.5087 - val_acc: 0.4504\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.4478 - acc: 0.4701 - val_loss: 1.7929 - val_acc: 0.4293\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "model 8/10 - generation 3/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.4893 - acc: 0.4681 - val_loss: 1.3619 - val_acc: 0.5084\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.2104 - acc: 0.5678 - val_loss: 1.1503 - val_acc: 0.5819\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.1022 - acc: 0.6072 - val_loss: 1.0876 - val_acc: 0.6123\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.0393 - acc: 0.6326 - val_loss: 1.0204 - val_acc: 0.6356\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.9806 - acc: 0.6541 - val_loss: 0.9761 - val_acc: 0.6548\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.9292 - acc: 0.6738 - val_loss: 0.9424 - val_acc: 0.6644\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.8921 - acc: 0.6868 - val_loss: 1.0344 - val_acc: 0.6372\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.8568 - acc: 0.6995 - val_loss: 1.1069 - val_acc: 0.6171\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 9/10 - generation 3/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 32s - loss: 1.7497 - acc: 0.4020 - val_loss: 1.4465 - val_acc: 0.4865\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 31s - loss: 1.2920 - acc: 0.5390 - val_loss: 1.2584 - val_acc: 0.5689\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 31s - loss: 1.1292 - acc: 0.5998 - val_loss: 1.1670 - val_acc: 0.5920\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 31s - loss: 1.0277 - acc: 0.6344 - val_loss: 0.9722 - val_acc: 0.6676\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 31s - loss: 0.9458 - acc: 0.6665 - val_loss: 1.0688 - val_acc: 0.6309\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 31s - loss: 0.8828 - acc: 0.6877 - val_loss: 0.8899 - val_acc: 0.6943\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 31s - loss: 0.8200 - acc: 0.7102 - val_loss: 0.8716 - val_acc: 0.6999\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 31s - loss: 0.7761 - acc: 0.7249 - val_loss: 0.8892 - val_acc: 0.6950\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 31s - loss: 0.7346 - acc: 0.7432 - val_loss: 0.8247 - val_acc: 0.7129\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 31s - loss: 0.6982 - acc: 0.7571 - val_loss: 0.7987 - val_acc: 0.7281\n",
      "\n",
      "model 10/10 - generation 3/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.3751 - acc: 0.5236 - val_loss: 1.1724 - val_acc: 0.5915\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9545 - acc: 0.6740 - val_loss: 1.0888 - val_acc: 0.6220\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8030 - acc: 0.7276 - val_loss: 1.1231 - val_acc: 0.6207\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.7005 - acc: 0.7668 - val_loss: 1.0660 - val_acc: 0.6390\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.6236 - acc: 0.7952 - val_loss: 1.0847 - val_acc: 0.6361\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.5599 - acc: 0.8190 - val_loss: 1.1015 - val_acc: 0.6353\n",
      "Epoch 00005: early stopping\n",
      "Generation 3:\t\tbest accuracy: 0.7281\t\taverage: 0.5755\t\tstd: 0.1018\n",
      "\n",
      "model 1/10 - generation 4/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 9s - loss: 1.6040 - acc: 0.4187 - val_loss: 1.3625 - val_acc: 0.5150\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 8s - loss: 1.3586 - acc: 0.5088 - val_loss: 1.2769 - val_acc: 0.5490\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 8s - loss: 1.2921 - acc: 0.5390 - val_loss: 1.2220 - val_acc: 0.5667\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 8s - loss: 1.2460 - acc: 0.5522 - val_loss: 1.1786 - val_acc: 0.5811\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 7s - loss: 1.2164 - acc: 0.5657 - val_loss: 1.1966 - val_acc: 0.5771\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 8s - loss: 1.1964 - acc: 0.5758 - val_loss: 1.2535 - val_acc: 0.5626\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "model 2/10 - generation 4/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.6302 - acc: 0.4102 - val_loss: 2.1425 - val_acc: 0.2672\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.2393 - acc: 0.5544 - val_loss: 1.2506 - val_acc: 0.5814\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.0802 - acc: 0.6179 - val_loss: 1.2114 - val_acc: 0.5818\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.9770 - acc: 0.6549 - val_loss: 1.1320 - val_acc: 0.6201\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9010 - acc: 0.6824 - val_loss: 1.0403 - val_acc: 0.6422\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.8389 - acc: 0.7038 - val_loss: 1.1100 - val_acc: 0.6020\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.7885 - acc: 0.7232 - val_loss: 0.9993 - val_acc: 0.6532\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.7490 - acc: 0.7383 - val_loss: 1.1776 - val_acc: 0.5805\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.7039 - acc: 0.7532 - val_loss: 0.8403 - val_acc: 0.7132\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.6688 - acc: 0.7642 - val_loss: 1.2277 - val_acc: 0.5779\n",
      "\n",
      "model 3/10 - generation 4/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 33s - loss: 1.7656 - acc: 0.3865 - val_loss: 1.4502 - val_acc: 0.4878\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 31s - loss: 1.3155 - acc: 0.5301 - val_loss: 1.2517 - val_acc: 0.5639\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 31s - loss: 1.1652 - acc: 0.5840 - val_loss: 1.3349 - val_acc: 0.5182\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 31s - loss: 1.0604 - acc: 0.6239 - val_loss: 2.0165 - val_acc: 0.3615\n",
      "Epoch 00003: early stopping\n",
      "\n",
      "model 4/10 - generation 4/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.5557 - acc: 0.4418 - val_loss: 1.7906 - val_acc: 0.3743\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.2093 - acc: 0.5646 - val_loss: 1.3223 - val_acc: 0.5351\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0596 - acc: 0.6231 - val_loss: 1.7895 - val_acc: 0.4048\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9802 - acc: 0.6542 - val_loss: 1.1778 - val_acc: 0.6000\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9217 - acc: 0.6749 - val_loss: 1.1628 - val_acc: 0.5791\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8795 - acc: 0.6930 - val_loss: 1.0073 - val_acc: 0.6571\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 19s - loss: 0.8383 - acc: 0.7047 - val_loss: 0.8991 - val_acc: 0.6924\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8028 - acc: 0.7183 - val_loss: 0.9518 - val_acc: 0.6666\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.7692 - acc: 0.7313 - val_loss: 0.9349 - val_acc: 0.6754\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 5/10 - generation 4/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.6356 - acc: 0.4186 - val_loss: 1.3269 - val_acc: 0.5301\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.3760 - acc: 0.5149 - val_loss: 1.3449 - val_acc: 0.5131\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2940 - acc: 0.5482 - val_loss: 1.5003 - val_acc: 0.4884\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "model 6/10 - generation 4/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.6185 - acc: 0.4235 - val_loss: 1.5246 - val_acc: 0.4516\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.3108 - acc: 0.5392 - val_loss: 1.3618 - val_acc: 0.5117\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1844 - acc: 0.5841 - val_loss: 1.2836 - val_acc: 0.5502\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0971 - acc: 0.6167 - val_loss: 1.2345 - val_acc: 0.5626\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0327 - acc: 0.6407 - val_loss: 1.1678 - val_acc: 0.5913\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9828 - acc: 0.6592 - val_loss: 1.1737 - val_acc: 0.5937\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9406 - acc: 0.6738 - val_loss: 1.1510 - val_acc: 0.6017\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8997 - acc: 0.6853 - val_loss: 1.1489 - val_acc: 0.6009\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8650 - acc: 0.6995 - val_loss: 1.1520 - val_acc: 0.6052\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8194 - acc: 0.7157 - val_loss: 1.1484 - val_acc: 0.6053\n",
      "\n",
      "model 7/10 - generation 4/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.5103 - acc: 0.4594 - val_loss: 1.5009 - val_acc: 0.4622\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2440 - acc: 0.5542 - val_loss: 1.4189 - val_acc: 0.5170\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1586 - acc: 0.5868 - val_loss: 1.2447 - val_acc: 0.5706\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0993 - acc: 0.6097 - val_loss: 1.1874 - val_acc: 0.5940\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0597 - acc: 0.6236 - val_loss: 1.0566 - val_acc: 0.6257\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0214 - acc: 0.6360 - val_loss: 1.1896 - val_acc: 0.5880\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9886 - acc: 0.6508 - val_loss: 1.1358 - val_acc: 0.6101\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 8/10 - generation 4/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 2.3504 - acc: 0.1266 - val_loss: 2.3237 - val_acc: 0.1262\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 2.0453 - acc: 0.2402 - val_loss: 1.8972 - val_acc: 0.3171\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.8237 - acc: 0.3344 - val_loss: 1.7273 - val_acc: 0.3533\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.6881 - acc: 0.3811 - val_loss: 1.7728 - val_acc: 0.3455\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.6013 - acc: 0.4151 - val_loss: 1.6077 - val_acc: 0.4097\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.5467 - acc: 0.4346 - val_loss: 1.5372 - val_acc: 0.4506\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.5050 - acc: 0.4564 - val_loss: 1.5263 - val_acc: 0.4512\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.4732 - acc: 0.4665 - val_loss: 1.5767 - val_acc: 0.4324\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.4347 - acc: 0.4831 - val_loss: 1.4338 - val_acc: 0.4823\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.3886 - acc: 0.5023 - val_loss: 1.4231 - val_acc: 0.4884\n",
      "\n",
      "model 9/10 - generation 4/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 1.4923 - acc: 0.4694 - val_loss: 1.2306 - val_acc: 0.5547\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.2108 - acc: 0.5701 - val_loss: 1.1228 - val_acc: 0.5931\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.0985 - acc: 0.6111 - val_loss: 1.0383 - val_acc: 0.6285\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.0248 - acc: 0.6357 - val_loss: 1.0367 - val_acc: 0.6337\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.9662 - acc: 0.6570 - val_loss: 1.0467 - val_acc: 0.6250\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 21s - loss: 0.9220 - acc: 0.6737 - val_loss: 0.9354 - val_acc: 0.6688\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 21s - loss: 0.8814 - acc: 0.6898 - val_loss: 0.9153 - val_acc: 0.6779\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 21s - loss: 0.8469 - acc: 0.7028 - val_loss: 0.9066 - val_acc: 0.6804\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.8147 - acc: 0.7150 - val_loss: 0.9883 - val_acc: 0.6605\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.7812 - acc: 0.7282 - val_loss: 0.8740 - val_acc: 0.6953\n",
      "\n",
      "model 10/10 - generation 4/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.7293 - acc: 0.3721 - val_loss: 1.5265 - val_acc: 0.4528\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.4492 - acc: 0.4773 - val_loss: 1.3586 - val_acc: 0.5084\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2968 - acc: 0.5391 - val_loss: 1.3058 - val_acc: 0.5346\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1782 - acc: 0.5844 - val_loss: 1.2005 - val_acc: 0.5723\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1070 - acc: 0.6110 - val_loss: 1.2143 - val_acc: 0.5737\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0530 - acc: 0.6300 - val_loss: 1.1343 - val_acc: 0.6013\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0143 - acc: 0.6435 - val_loss: 1.1090 - val_acc: 0.6062\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9836 - acc: 0.6551 - val_loss: 1.1122 - val_acc: 0.6046\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9581 - acc: 0.6630 - val_loss: 1.0798 - val_acc: 0.6171\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9340 - acc: 0.6720 - val_loss: 1.1115 - val_acc: 0.6128\n",
      "Generation 4:\t\tbest accuracy: 0.6953\t\taverage: 0.5678\t\tstd: 0.0940\n",
      "\n",
      "model 1/10 - generation 5/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.7350 - acc: 0.3788 - val_loss: 1.5011 - val_acc: 0.4714\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.3805 - acc: 0.5101 - val_loss: 1.3219 - val_acc: 0.5272\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2129 - acc: 0.5746 - val_loss: 1.2022 - val_acc: 0.5746\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1184 - acc: 0.6080 - val_loss: 1.2092 - val_acc: 0.5743\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0565 - acc: 0.6314 - val_loss: 1.1341 - val_acc: 0.6058\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0039 - acc: 0.6507 - val_loss: 1.1288 - val_acc: 0.6126\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9603 - acc: 0.6646 - val_loss: 1.0937 - val_acc: 0.6168\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9216 - acc: 0.6812 - val_loss: 1.0903 - val_acc: 0.6212\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8895 - acc: 0.6899 - val_loss: 1.0799 - val_acc: 0.6296\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8633 - acc: 0.6979 - val_loss: 1.0903 - val_acc: 0.6202\n",
      "\n",
      "model 2/10 - generation 5/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 32s - loss: 2.9708 - acc: 0.1064 - val_loss: 2.4341 - val_acc: 0.1000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 31s - loss: 2.3029 - acc: 0.1000 - val_loss: 2.3292 - val_acc: 0.1000\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 31s - loss: 2.3028 - acc: 0.0981 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 30s - loss: 2.3031 - acc: 0.0986 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 30s - loss: 2.3029 - acc: 0.1009 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 30s - loss: 2.3028 - acc: 0.0996 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "model 3/10 - generation 5/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.5715 - acc: 0.4355 - val_loss: 1.6220 - val_acc: 0.4269\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.2230 - acc: 0.5617 - val_loss: 1.8014 - val_acc: 0.3949\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0858 - acc: 0.6149 - val_loss: 1.1493 - val_acc: 0.6012\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9963 - acc: 0.6501 - val_loss: 1.3690 - val_acc: 0.5181\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9222 - acc: 0.6770 - val_loss: 1.0216 - val_acc: 0.6412\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8795 - acc: 0.6910 - val_loss: 0.8763 - val_acc: 0.6974\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8327 - acc: 0.7070 - val_loss: 0.8803 - val_acc: 0.6941\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.7925 - acc: 0.7204 - val_loss: 0.8751 - val_acc: 0.6974\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.7613 - acc: 0.7323 - val_loss: 0.8742 - val_acc: 0.6958\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.7350 - acc: 0.7404 - val_loss: 0.8746 - val_acc: 0.6979\n",
      "\n",
      "model 4/10 - generation 5/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.6105 - acc: 0.4372 - val_loss: 1.6817 - val_acc: 0.4151\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2612 - acc: 0.5512 - val_loss: 1.2591 - val_acc: 0.5452\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1561 - acc: 0.5912 - val_loss: 2.6326 - val_acc: 0.3547\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0922 - acc: 0.6181 - val_loss: 1.2113 - val_acc: 0.5818\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0489 - acc: 0.6341 - val_loss: 1.2722 - val_acc: 0.5700\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0170 - acc: 0.6470 - val_loss: 1.0900 - val_acc: 0.6157\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9941 - acc: 0.6528 - val_loss: 1.8314 - val_acc: 0.4688\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9784 - acc: 0.6616 - val_loss: 2.3206 - val_acc: 0.4037\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 5/10 - generation 5/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 1.5003 - acc: 0.4642 - val_loss: 1.6878 - val_acc: 0.4360\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.2439 - acc: 0.5544 - val_loss: 1.3007 - val_acc: 0.5442\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.1402 - acc: 0.5932 - val_loss: 1.0950 - val_acc: 0.6079\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.0643 - acc: 0.6218 - val_loss: 1.0537 - val_acc: 0.6255\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.0114 - acc: 0.6408 - val_loss: 1.0226 - val_acc: 0.6380\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 21s - loss: 0.9623 - acc: 0.6598 - val_loss: 1.0211 - val_acc: 0.6386\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 21s - loss: 0.9201 - acc: 0.6759 - val_loss: 0.9769 - val_acc: 0.6550\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 21s - loss: 0.8878 - acc: 0.6894 - val_loss: 0.9225 - val_acc: 0.6739\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 21s - loss: 0.8598 - acc: 0.6964 - val_loss: 0.9081 - val_acc: 0.6843\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 21s - loss: 0.8287 - acc: 0.7080 - val_loss: 0.9109 - val_acc: 0.6848\n",
      "\n",
      "model 6/10 - generation 5/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 2.1629 - acc: 0.2427 - val_loss: 1.9809 - val_acc: 0.2762\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.6758 - acc: 0.3871 - val_loss: 1.7669 - val_acc: 0.3653\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.5683 - acc: 0.4324 - val_loss: 1.6162 - val_acc: 0.4175\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.5005 - acc: 0.4562 - val_loss: 1.7128 - val_acc: 0.3911\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.4530 - acc: 0.4769 - val_loss: 1.5389 - val_acc: 0.4505\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.4001 - acc: 0.4980 - val_loss: 1.4906 - val_acc: 0.4715\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.3532 - acc: 0.5158 - val_loss: 1.4229 - val_acc: 0.4990\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.3188 - acc: 0.5271 - val_loss: 1.4861 - val_acc: 0.4864\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2784 - acc: 0.5442 - val_loss: 1.3096 - val_acc: 0.5348\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2562 - acc: 0.5524 - val_loss: 1.4723 - val_acc: 0.4813\n",
      "\n",
      "model 7/10 - generation 5/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.5238 - acc: 0.4482 - val_loss: 1.6110 - val_acc: 0.4404\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2861 - acc: 0.5385 - val_loss: 1.3932 - val_acc: 0.5137\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1912 - acc: 0.5763 - val_loss: 1.3224 - val_acc: 0.5313\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1356 - acc: 0.5954 - val_loss: 1.2169 - val_acc: 0.5709\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0935 - acc: 0.6110 - val_loss: 1.2160 - val_acc: 0.5814\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0565 - acc: 0.6271 - val_loss: 1.2889 - val_acc: 0.5552\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0280 - acc: 0.6356 - val_loss: 1.0948 - val_acc: 0.6164\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0063 - acc: 0.6433 - val_loss: 1.2543 - val_acc: 0.5636\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9816 - acc: 0.6532 - val_loss: 1.0641 - val_acc: 0.6320\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9628 - acc: 0.6607 - val_loss: 1.0477 - val_acc: 0.6323\n",
      "\n",
      "model 8/10 - generation 5/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 24s - loss: 3.0424 - acc: 0.1058 - val_loss: 2.3031 - val_acc: 0.1000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 23s - loss: 2.3035 - acc: 0.1003 - val_loss: 2.3030 - val_acc: 0.1000\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 23s - loss: 2.3029 - acc: 0.0992 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 23s - loss: 2.3033 - acc: 0.0992 - val_loss: 2.3028 - val_acc: 0.1000\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 23s - loss: 2.3030 - acc: 0.0986 - val_loss: 2.3027 - val_acc: 0.1000\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 23s - loss: 2.3028 - acc: 0.0992 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 23s - loss: 2.3028 - acc: 0.0969 - val_loss: 2.3032 - val_acc: 0.1000\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 23s - loss: 2.3028 - acc: 0.0987 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 9/10 - generation 5/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.8432 - acc: 0.4727 - val_loss: 1.3655 - val_acc: 0.5125\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1393 - acc: 0.6018 - val_loss: 1.2043 - val_acc: 0.5792\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0206 - acc: 0.6432 - val_loss: 1.1094 - val_acc: 0.6149\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9556 - acc: 0.6691 - val_loss: 1.2394 - val_acc: 0.5534\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9072 - acc: 0.6866 - val_loss: 1.0635 - val_acc: 0.6242\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8692 - acc: 0.6998 - val_loss: 1.1063 - val_acc: 0.6094\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8474 - acc: 0.7060 - val_loss: 1.0407 - val_acc: 0.6342\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8200 - acc: 0.7179 - val_loss: 1.0400 - val_acc: 0.6361\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.8020 - acc: 0.7230 - val_loss: 0.9600 - val_acc: 0.6678\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.7814 - acc: 0.7307 - val_loss: 1.0239 - val_acc: 0.6421\n",
      "\n",
      "model 10/10 - generation 5/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 9s - loss: 1.6193 - acc: 0.4090 - val_loss: 1.4282 - val_acc: 0.4820\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 8s - loss: 1.3896 - acc: 0.4977 - val_loss: 1.3121 - val_acc: 0.5275\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 8s - loss: 1.3164 - acc: 0.5289 - val_loss: 1.2634 - val_acc: 0.5522\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 8s - loss: 1.2702 - acc: 0.5471 - val_loss: 1.2870 - val_acc: 0.5455\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 8s - loss: 1.2399 - acc: 0.5586 - val_loss: 1.2399 - val_acc: 0.5542\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 8s - loss: 1.2152 - acc: 0.5669 - val_loss: 1.1955 - val_acc: 0.5790\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 8s - loss: 1.1938 - acc: 0.5755 - val_loss: 1.1770 - val_acc: 0.5803\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 8s - loss: 1.1771 - acc: 0.5841 - val_loss: 1.1276 - val_acc: 0.6025\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 8s - loss: 1.1639 - acc: 0.5897 - val_loss: 1.1399 - val_acc: 0.6002\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 8s - loss: 1.1558 - acc: 0.5933 - val_loss: 1.1170 - val_acc: 0.6111\n",
      "Generation 5:\t\tbest accuracy: 0.6979\t\taverage: 0.4973\t\tstd: 0.2162\n",
      "\n",
      "model 1/10 - generation 6/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.6786 - acc: 0.3991 - val_loss: 1.4819 - val_acc: 0.4791\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.3021 - acc: 0.5393 - val_loss: 1.2538 - val_acc: 0.5566\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1497 - acc: 0.5946 - val_loss: 1.2024 - val_acc: 0.5781\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0609 - acc: 0.6282 - val_loss: 1.1139 - val_acc: 0.6138\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9935 - acc: 0.6531 - val_loss: 1.1418 - val_acc: 0.6032\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9488 - acc: 0.6700 - val_loss: 1.0616 - val_acc: 0.6340\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9144 - acc: 0.6839 - val_loss: 1.0786 - val_acc: 0.6293\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8840 - acc: 0.6911 - val_loss: 1.0855 - val_acc: 0.6312\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 2/10 - generation 6/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 1.6198 - acc: 0.4165 - val_loss: 2.7352 - val_acc: 0.1921\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.3013 - acc: 0.5335 - val_loss: 2.2627 - val_acc: 0.2568\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.1689 - acc: 0.5842 - val_loss: 2.4671 - val_acc: 0.2680\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.0780 - acc: 0.6184 - val_loss: 1.4823 - val_acc: 0.4859\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.0074 - acc: 0.6454 - val_loss: 1.7322 - val_acc: 0.3918\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 21s - loss: 0.9495 - acc: 0.6655 - val_loss: 2.5178 - val_acc: 0.2594\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "model 3/10 - generation 6/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.5684 - acc: 0.4397 - val_loss: 1.6086 - val_acc: 0.4204\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.2950 - acc: 0.5339 - val_loss: 1.9621 - val_acc: 0.3525\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.1984 - acc: 0.5685 - val_loss: 1.4086 - val_acc: 0.4975\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.1420 - acc: 0.5928 - val_loss: 1.2659 - val_acc: 0.5530\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.1014 - acc: 0.6073 - val_loss: 1.2713 - val_acc: 0.5556\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.0693 - acc: 0.6186 - val_loss: 1.1404 - val_acc: 0.5928\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.0364 - acc: 0.6319 - val_loss: 1.3842 - val_acc: 0.5276\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.0158 - acc: 0.6422 - val_loss: 1.1694 - val_acc: 0.5918\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 4/10 - generation 6/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.6202 - acc: 0.4326 - val_loss: 1.6231 - val_acc: 0.4248\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.2600 - acc: 0.5511 - val_loss: 1.2388 - val_acc: 0.5721\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.1247 - acc: 0.5982 - val_loss: 1.2816 - val_acc: 0.5471\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0254 - acc: 0.6356 - val_loss: 1.0711 - val_acc: 0.6275\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9599 - acc: 0.6605 - val_loss: 0.9869 - val_acc: 0.6448\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8958 - acc: 0.6821 - val_loss: 1.3096 - val_acc: 0.5706\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8536 - acc: 0.7002 - val_loss: 1.9143 - val_acc: 0.4633\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 5/10 - generation 6/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.6802 - acc: 0.3912 - val_loss: 1.6557 - val_acc: 0.4048\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 14s - loss: 1.4176 - acc: 0.4900 - val_loss: 1.4317 - val_acc: 0.4812\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.3202 - acc: 0.5298 - val_loss: 1.3055 - val_acc: 0.5395\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2419 - acc: 0.5585 - val_loss: 1.2295 - val_acc: 0.5621\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1919 - acc: 0.5771 - val_loss: 1.2244 - val_acc: 0.5715\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1510 - acc: 0.5915 - val_loss: 1.1778 - val_acc: 0.5872\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1234 - acc: 0.6039 - val_loss: 1.1695 - val_acc: 0.5886\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0982 - acc: 0.6117 - val_loss: 1.1829 - val_acc: 0.5813\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0806 - acc: 0.6196 - val_loss: 1.1583 - val_acc: 0.5911\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0588 - acc: 0.6286 - val_loss: 1.1646 - val_acc: 0.5930\n",
      "\n",
      "model 6/10 - generation 6/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.9213 - acc: 0.4656 - val_loss: 1.4248 - val_acc: 0.4928\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1733 - acc: 0.5871 - val_loss: 1.2809 - val_acc: 0.5471\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0634 - acc: 0.6286 - val_loss: 1.2971 - val_acc: 0.5361\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9899 - acc: 0.6549 - val_loss: 1.1645 - val_acc: 0.5976\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9362 - acc: 0.6749 - val_loss: 1.1115 - val_acc: 0.6137\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.8946 - acc: 0.6907 - val_loss: 1.0888 - val_acc: 0.6253\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.8614 - acc: 0.7017 - val_loss: 1.0351 - val_acc: 0.6428\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.8347 - acc: 0.7124 - val_loss: 1.0110 - val_acc: 0.6474\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.8119 - acc: 0.7197 - val_loss: 0.9766 - val_acc: 0.6617\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.7905 - acc: 0.7276 - val_loss: 1.0640 - val_acc: 0.6245\n",
      "\n",
      "model 7/10 - generation 6/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.7533 - acc: 0.3841 - val_loss: 1.5764 - val_acc: 0.4617\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.3868 - acc: 0.5076 - val_loss: 1.3625 - val_acc: 0.5206\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2611 - acc: 0.5548 - val_loss: 1.3594 - val_acc: 0.5295\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2013 - acc: 0.5791 - val_loss: 1.2271 - val_acc: 0.5709\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1606 - acc: 0.5906 - val_loss: 1.2047 - val_acc: 0.5898\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1308 - acc: 0.6049 - val_loss: 1.1834 - val_acc: 0.5952\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1042 - acc: 0.6115 - val_loss: 1.1837 - val_acc: 0.5849\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0870 - acc: 0.6202 - val_loss: 1.1701 - val_acc: 0.6010\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0669 - acc: 0.6259 - val_loss: 1.1431 - val_acc: 0.6083\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0485 - acc: 0.6343 - val_loss: 1.1125 - val_acc: 0.6129\n",
      "\n",
      "model 8/10 - generation 6/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.4924 - acc: 0.4634 - val_loss: 1.5571 - val_acc: 0.4373\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.1205 - acc: 0.6011 - val_loss: 1.1735 - val_acc: 0.6087\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9800 - acc: 0.6519 - val_loss: 1.2771 - val_acc: 0.5509\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.8874 - acc: 0.6854 - val_loss: 0.9320 - val_acc: 0.6928\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8258 - acc: 0.7089 - val_loss: 1.0457 - val_acc: 0.6339\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 20s - loss: 0.7688 - acc: 0.7279 - val_loss: 1.0378 - val_acc: 0.6458\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "model 9/10 - generation 6/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.6990 - acc: 0.3886 - val_loss: 1.4428 - val_acc: 0.4821\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3587 - acc: 0.5207 - val_loss: 1.3679 - val_acc: 0.5254\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2241 - acc: 0.5703 - val_loss: 1.2164 - val_acc: 0.5730\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1282 - acc: 0.6051 - val_loss: 1.1980 - val_acc: 0.5809\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0537 - acc: 0.6318 - val_loss: 1.1521 - val_acc: 0.5953\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0018 - acc: 0.6492 - val_loss: 1.1474 - val_acc: 0.6002\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9604 - acc: 0.6652 - val_loss: 1.1435 - val_acc: 0.6041\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9250 - acc: 0.6781 - val_loss: 1.0849 - val_acc: 0.6205\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8938 - acc: 0.6872 - val_loss: 1.0749 - val_acc: 0.6230\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8646 - acc: 0.6989 - val_loss: 1.0811 - val_acc: 0.6233\n",
      "\n",
      "model 10/10 - generation 6/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.6973 - acc: 0.4128 - val_loss: 2.1192 - val_acc: 0.4201\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2754 - acc: 0.5514 - val_loss: 1.4068 - val_acc: 0.5266\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1530 - acc: 0.5942 - val_loss: 1.1849 - val_acc: 0.5852\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0764 - acc: 0.6227 - val_loss: 1.2259 - val_acc: 0.5793\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0088 - acc: 0.6464 - val_loss: 1.1063 - val_acc: 0.6148\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9601 - acc: 0.6648 - val_loss: 1.1086 - val_acc: 0.6105\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9215 - acc: 0.6780 - val_loss: 1.1112 - val_acc: 0.6108\n",
      "Epoch 00006: early stopping\n",
      "Generation 6:\t\tbest accuracy: 0.6458\t\taverage: 0.5656\t\tstd: 0.1129\n",
      "\n",
      "model 1/10 - generation 7/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.6242 - acc: 0.4183 - val_loss: 1.3121 - val_acc: 0.5301\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2349 - acc: 0.5670 - val_loss: 1.2118 - val_acc: 0.5733\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1074 - acc: 0.6155 - val_loss: 1.1451 - val_acc: 0.5983\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0075 - acc: 0.6504 - val_loss: 1.1166 - val_acc: 0.6193\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9278 - acc: 0.6768 - val_loss: 1.1312 - val_acc: 0.6114\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8667 - acc: 0.6991 - val_loss: 1.0709 - val_acc: 0.6326\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8163 - acc: 0.7185 - val_loss: 1.0790 - val_acc: 0.6334\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.7732 - acc: 0.7327 - val_loss: 1.0938 - val_acc: 0.6298\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 2/10 - generation 7/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.6898 - acc: 0.4496 - val_loss: 1.4891 - val_acc: 0.4665\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.2545 - acc: 0.5572 - val_loss: 1.1869 - val_acc: 0.5868\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.1549 - acc: 0.5930 - val_loss: 1.1633 - val_acc: 0.5936\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.0877 - acc: 0.6179 - val_loss: 1.0865 - val_acc: 0.6297\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 11s - loss: 1.0447 - acc: 0.6330 - val_loss: 1.0873 - val_acc: 0.6273\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.0049 - acc: 0.6477 - val_loss: 1.0765 - val_acc: 0.6230\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 12s - loss: 0.9783 - acc: 0.6604 - val_loss: 1.0737 - val_acc: 0.6255\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 12s - loss: 0.9551 - acc: 0.6683 - val_loss: 0.9912 - val_acc: 0.6613\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 12s - loss: 0.9396 - acc: 0.6731 - val_loss: 1.0228 - val_acc: 0.6440\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 12s - loss: 0.9225 - acc: 0.6795 - val_loss: 0.9653 - val_acc: 0.6758\n",
      "\n",
      "model 3/10 - generation 7/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.8931 - acc: 0.4694 - val_loss: 1.4264 - val_acc: 0.4990\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1484 - acc: 0.5960 - val_loss: 1.2658 - val_acc: 0.5537\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0406 - acc: 0.6372 - val_loss: 1.1289 - val_acc: 0.6072\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9681 - acc: 0.6615 - val_loss: 1.0665 - val_acc: 0.6209\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9140 - acc: 0.6815 - val_loss: 1.0282 - val_acc: 0.6481\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8757 - acc: 0.6978 - val_loss: 1.0713 - val_acc: 0.6248\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8440 - acc: 0.7087 - val_loss: 0.9862 - val_acc: 0.6626\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8180 - acc: 0.7164 - val_loss: 1.0873 - val_acc: 0.6180\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.7967 - acc: 0.7233 - val_loss: 0.9651 - val_acc: 0.6631\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.7744 - acc: 0.7324 - val_loss: 1.0213 - val_acc: 0.6392\n",
      "\n",
      "model 4/10 - generation 7/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.6588 - acc: 0.4030 - val_loss: 1.3607 - val_acc: 0.5137\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2672 - acc: 0.5548 - val_loss: 1.2254 - val_acc: 0.5697\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1500 - acc: 0.5982 - val_loss: 1.1826 - val_acc: 0.5863\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0903 - acc: 0.6208 - val_loss: 1.1445 - val_acc: 0.5982\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0399 - acc: 0.6381 - val_loss: 1.1112 - val_acc: 0.6122\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9930 - acc: 0.6533 - val_loss: 1.1180 - val_acc: 0.6195\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9437 - acc: 0.6699 - val_loss: 1.0655 - val_acc: 0.6296\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9024 - acc: 0.6862 - val_loss: 1.0383 - val_acc: 0.6417\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8680 - acc: 0.6989 - val_loss: 1.0343 - val_acc: 0.6461\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8398 - acc: 0.7080 - val_loss: 1.0332 - val_acc: 0.6447\n",
      "\n",
      "model 5/10 - generation 7/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.6972 - acc: 0.3977 - val_loss: 1.5075 - val_acc: 0.4948\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.3443 - acc: 0.5253 - val_loss: 1.3290 - val_acc: 0.5437\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2325 - acc: 0.5658 - val_loss: 1.2788 - val_acc: 0.5599\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1753 - acc: 0.5858 - val_loss: 1.2372 - val_acc: 0.5732\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1366 - acc: 0.6000 - val_loss: 1.2049 - val_acc: 0.5825\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1054 - acc: 0.6138 - val_loss: 1.1617 - val_acc: 0.6004\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0772 - acc: 0.6207 - val_loss: 1.1441 - val_acc: 0.6057\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0541 - acc: 0.6306 - val_loss: 1.1217 - val_acc: 0.6142\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0350 - acc: 0.6391 - val_loss: 1.1367 - val_acc: 0.6092\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0145 - acc: 0.6463 - val_loss: 1.1511 - val_acc: 0.5942\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "model 6/10 - generation 7/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.5057 - acc: 0.4733 - val_loss: 1.4312 - val_acc: 0.5099\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2182 - acc: 0.5836 - val_loss: 1.4875 - val_acc: 0.5311\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1360 - acc: 0.6141 - val_loss: 1.4113 - val_acc: 0.5276\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0887 - acc: 0.6305 - val_loss: 1.2343 - val_acc: 0.5920\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0520 - acc: 0.6413 - val_loss: 1.3135 - val_acc: 0.5539\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0135 - acc: 0.6548 - val_loss: 1.1555 - val_acc: 0.5992\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9893 - acc: 0.6576 - val_loss: 1.2842 - val_acc: 0.5750\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9672 - acc: 0.6689 - val_loss: 1.6194 - val_acc: 0.4766\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 7/10 - generation 7/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.7071 - acc: 0.4036 - val_loss: 1.5245 - val_acc: 0.4678\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.3357 - acc: 0.5313 - val_loss: 1.3002 - val_acc: 0.5438\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2094 - acc: 0.5749 - val_loss: 1.2470 - val_acc: 0.5581\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1213 - acc: 0.6077 - val_loss: 1.1301 - val_acc: 0.5992\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0195 - acc: 0.6451 - val_loss: 1.1189 - val_acc: 0.6042\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9472 - acc: 0.6709 - val_loss: 1.0810 - val_acc: 0.6215\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8930 - acc: 0.6891 - val_loss: 1.0780 - val_acc: 0.6277\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8450 - acc: 0.7056 - val_loss: 1.0575 - val_acc: 0.6315\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8057 - acc: 0.7188 - val_loss: 1.1296 - val_acc: 0.6167\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.7667 - acc: 0.7346 - val_loss: 1.0611 - val_acc: 0.6384\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "model 8/10 - generation 7/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 18s - loss: 1.6300 - acc: 0.4245 - val_loss: 1.3512 - val_acc: 0.5204\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2756 - acc: 0.5494 - val_loss: 1.2468 - val_acc: 0.5566\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1483 - acc: 0.5990 - val_loss: 1.1865 - val_acc: 0.5895\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0716 - acc: 0.6275 - val_loss: 1.1079 - val_acc: 0.6155\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0122 - acc: 0.6482 - val_loss: 1.1556 - val_acc: 0.5998\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9735 - acc: 0.6621 - val_loss: 1.0768 - val_acc: 0.6292\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9346 - acc: 0.6763 - val_loss: 1.2006 - val_acc: 0.5997\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9046 - acc: 0.6845 - val_loss: 1.0713 - val_acc: 0.6261\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8805 - acc: 0.6930 - val_loss: 1.0562 - val_acc: 0.6320\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8568 - acc: 0.7001 - val_loss: 1.0385 - val_acc: 0.6434\n",
      "\n",
      "model 9/10 - generation 7/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.6704 - acc: 0.3979 - val_loss: 1.4885 - val_acc: 0.4705\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.3738 - acc: 0.5106 - val_loss: 1.3960 - val_acc: 0.4996\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2737 - acc: 0.5479 - val_loss: 1.3224 - val_acc: 0.5314\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2176 - acc: 0.5701 - val_loss: 1.2843 - val_acc: 0.5485\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1798 - acc: 0.5832 - val_loss: 1.2688 - val_acc: 0.5666\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1408 - acc: 0.5989 - val_loss: 1.2337 - val_acc: 0.5680\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1157 - acc: 0.6076 - val_loss: 1.1647 - val_acc: 0.5918\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0899 - acc: 0.6164 - val_loss: 1.1605 - val_acc: 0.5882\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0656 - acc: 0.6241 - val_loss: 1.1981 - val_acc: 0.5809\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0432 - acc: 0.6335 - val_loss: 1.1541 - val_acc: 0.6002\n",
      "\n",
      "model 10/10 - generation 7/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.6175 - acc: 0.4192 - val_loss: 1.4503 - val_acc: 0.4866\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3118 - acc: 0.5355 - val_loss: 1.3151 - val_acc: 0.5364\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2077 - acc: 0.5724 - val_loss: 1.2004 - val_acc: 0.5753\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1289 - acc: 0.6057 - val_loss: 1.1484 - val_acc: 0.5889\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0515 - acc: 0.6311 - val_loss: 1.2570 - val_acc: 0.5663\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9817 - acc: 0.6570 - val_loss: 1.0869 - val_acc: 0.6230\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9361 - acc: 0.6730 - val_loss: 1.1126 - val_acc: 0.6129\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8961 - acc: 0.6885 - val_loss: 1.0601 - val_acc: 0.6308\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8669 - acc: 0.6969 - val_loss: 1.0658 - val_acc: 0.6321\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8410 - acc: 0.7056 - val_loss: 1.0612 - val_acc: 0.6347\n",
      "Epoch 00009: early stopping\n",
      "Generation 7:\t\tbest accuracy: 0.6758\t\taverage: 0.6177\t\tstd: 0.0518\n",
      "\n",
      "model 1/10 - generation 8/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.7275 - acc: 0.3747 - val_loss: 1.7291 - val_acc: 0.3895\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3719 - acc: 0.5100 - val_loss: 1.2984 - val_acc: 0.5383\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2215 - acc: 0.5667 - val_loss: 1.2467 - val_acc: 0.5562\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1344 - acc: 0.5988 - val_loss: 1.2042 - val_acc: 0.5803\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0702 - acc: 0.6239 - val_loss: 1.1313 - val_acc: 0.6014\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0231 - acc: 0.6426 - val_loss: 1.1093 - val_acc: 0.6112\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9838 - acc: 0.6546 - val_loss: 1.0930 - val_acc: 0.6192\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9476 - acc: 0.6701 - val_loss: 1.1309 - val_acc: 0.6105\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9192 - acc: 0.6754 - val_loss: 1.0766 - val_acc: 0.6276\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8980 - acc: 0.6852 - val_loss: 1.0341 - val_acc: 0.6400\n",
      "\n",
      "model 2/10 - generation 8/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 14s - loss: 2.0228 - acc: 0.4297 - val_loss: 1.5625 - val_acc: 0.4353\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.2805 - acc: 0.5444 - val_loss: 1.5028 - val_acc: 0.4810\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.1631 - acc: 0.5870 - val_loss: 1.4842 - val_acc: 0.4960\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.0914 - acc: 0.6151 - val_loss: 1.2230 - val_acc: 0.5716\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.0402 - acc: 0.6341 - val_loss: 1.1120 - val_acc: 0.6137\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.0044 - acc: 0.6472 - val_loss: 1.1150 - val_acc: 0.6136\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 12s - loss: 0.9720 - acc: 0.6600 - val_loss: 1.0951 - val_acc: 0.6252\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 12s - loss: 0.9447 - acc: 0.6689 - val_loss: 1.0909 - val_acc: 0.6249\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 12s - loss: 0.9230 - acc: 0.6788 - val_loss: 1.0695 - val_acc: 0.6331\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 12s - loss: 0.9033 - acc: 0.6828 - val_loss: 1.0088 - val_acc: 0.6591\n",
      "\n",
      "model 3/10 - generation 8/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.6313 - acc: 0.4232 - val_loss: 1.3590 - val_acc: 0.5192\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3004 - acc: 0.5417 - val_loss: 1.3112 - val_acc: 0.5300\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1926 - acc: 0.5823 - val_loss: 1.2752 - val_acc: 0.5512\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1257 - acc: 0.6065 - val_loss: 1.1526 - val_acc: 0.5961\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0738 - acc: 0.6259 - val_loss: 1.1264 - val_acc: 0.6029\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0297 - acc: 0.6414 - val_loss: 1.0997 - val_acc: 0.6141\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9890 - acc: 0.6551 - val_loss: 1.0857 - val_acc: 0.6217\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9558 - acc: 0.6667 - val_loss: 1.1669 - val_acc: 0.5977\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9315 - acc: 0.6753 - val_loss: 1.1666 - val_acc: 0.6012\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 4/10 - generation 8/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 6.1975 - acc: 0.2721 - val_loss: 1.4927 - val_acc: 0.4656\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3925 - acc: 0.5062 - val_loss: 1.4998 - val_acc: 0.4664\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2460 - acc: 0.5581 - val_loss: 1.2343 - val_acc: 0.5655\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1496 - acc: 0.5958 - val_loss: 1.1827 - val_acc: 0.5875\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0647 - acc: 0.6269 - val_loss: 1.1910 - val_acc: 0.5852\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0007 - acc: 0.6507 - val_loss: 1.1275 - val_acc: 0.6025\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9416 - acc: 0.6700 - val_loss: 1.2928 - val_acc: 0.5624\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8942 - acc: 0.6863 - val_loss: 1.0453 - val_acc: 0.6462\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8514 - acc: 0.7034 - val_loss: 1.0992 - val_acc: 0.6302\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8205 - acc: 0.7135 - val_loss: 1.0434 - val_acc: 0.6448\n",
      "\n",
      "model 5/10 - generation 8/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.8141 - acc: 0.3466 - val_loss: 1.6078 - val_acc: 0.4274\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.4871 - acc: 0.4656 - val_loss: 1.4194 - val_acc: 0.4945\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.3566 - acc: 0.5158 - val_loss: 1.3550 - val_acc: 0.5208\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2953 - acc: 0.5391 - val_loss: 1.2987 - val_acc: 0.5365\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2413 - acc: 0.5625 - val_loss: 1.2751 - val_acc: 0.5472\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2028 - acc: 0.5745 - val_loss: 1.2227 - val_acc: 0.5648\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1736 - acc: 0.5866 - val_loss: 1.2276 - val_acc: 0.5630\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1501 - acc: 0.5940 - val_loss: 1.2425 - val_acc: 0.5634\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 6/10 - generation 8/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.6400 - acc: 0.4183 - val_loss: 1.4928 - val_acc: 0.4887\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.3190 - acc: 0.5339 - val_loss: 1.2732 - val_acc: 0.5571\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1990 - acc: 0.5772 - val_loss: 1.2111 - val_acc: 0.5890\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1226 - acc: 0.6081 - val_loss: 1.1815 - val_acc: 0.5888\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0686 - acc: 0.6293 - val_loss: 1.1277 - val_acc: 0.6122\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0363 - acc: 0.6394 - val_loss: 1.1045 - val_acc: 0.6256\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0103 - acc: 0.6495 - val_loss: 1.1250 - val_acc: 0.6160\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9858 - acc: 0.6561 - val_loss: 1.0516 - val_acc: 0.6399\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9635 - acc: 0.6652 - val_loss: 1.0603 - val_acc: 0.6370\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9500 - acc: 0.6700 - val_loss: 1.0595 - val_acc: 0.6349\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "model 7/10 - generation 8/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.7724 - acc: 0.3874 - val_loss: 1.6467 - val_acc: 0.4001\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.4379 - acc: 0.4840 - val_loss: 1.4555 - val_acc: 0.4761\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3319 - acc: 0.5263 - val_loss: 1.3987 - val_acc: 0.5036\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2554 - acc: 0.5550 - val_loss: 1.2717 - val_acc: 0.5511\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1796 - acc: 0.5840 - val_loss: 1.2719 - val_acc: 0.5493\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1100 - acc: 0.6098 - val_loss: 1.1694 - val_acc: 0.5911\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0335 - acc: 0.6387 - val_loss: 1.1495 - val_acc: 0.5988\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9824 - acc: 0.6579 - val_loss: 1.0995 - val_acc: 0.6195\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9430 - acc: 0.6698 - val_loss: 1.1301 - val_acc: 0.6100\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9163 - acc: 0.6811 - val_loss: 1.0609 - val_acc: 0.6357\n",
      "\n",
      "model 8/10 - generation 8/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.7232 - acc: 0.3834 - val_loss: 1.4496 - val_acc: 0.4775\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3683 - acc: 0.5145 - val_loss: 1.3490 - val_acc: 0.5162\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2332 - acc: 0.5635 - val_loss: 1.2319 - val_acc: 0.5617\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1411 - acc: 0.5984 - val_loss: 1.1811 - val_acc: 0.5854\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0815 - acc: 0.6185 - val_loss: 1.1539 - val_acc: 0.5928\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0282 - acc: 0.6401 - val_loss: 1.1572 - val_acc: 0.5970\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9870 - acc: 0.6543 - val_loss: 1.2289 - val_acc: 0.5755\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 9/10 - generation 8/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.7739 - acc: 0.3547 - val_loss: 1.5658 - val_acc: 0.4344\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.4847 - acc: 0.4694 - val_loss: 1.4103 - val_acc: 0.4879\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.3764 - acc: 0.5123 - val_loss: 1.3571 - val_acc: 0.5153\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.3075 - acc: 0.5398 - val_loss: 1.3016 - val_acc: 0.5345\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2496 - acc: 0.5594 - val_loss: 1.2613 - val_acc: 0.5509\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2096 - acc: 0.5734 - val_loss: 1.2488 - val_acc: 0.5545\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1767 - acc: 0.5872 - val_loss: 1.2182 - val_acc: 0.5689\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1429 - acc: 0.5992 - val_loss: 1.2207 - val_acc: 0.5670\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1142 - acc: 0.6080 - val_loss: 1.1525 - val_acc: 0.5952\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0879 - acc: 0.6180 - val_loss: 1.1204 - val_acc: 0.6086\n",
      "\n",
      "model 10/10 - generation 8/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.6820 - acc: 0.3955 - val_loss: 1.3693 - val_acc: 0.5138\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2738 - acc: 0.5513 - val_loss: 1.2411 - val_acc: 0.5596\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1422 - acc: 0.5991 - val_loss: 1.1696 - val_acc: 0.5908\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0596 - acc: 0.6286 - val_loss: 1.1258 - val_acc: 0.6050\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 15s - loss: 0.9947 - acc: 0.6524 - val_loss: 1.1206 - val_acc: 0.6119\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9459 - acc: 0.6720 - val_loss: 1.1270 - val_acc: 0.6129\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8975 - acc: 0.6860 - val_loss: 1.1576 - val_acc: 0.6091\n",
      "Epoch 00006: early stopping\n",
      "Generation 8:\t\tbest accuracy: 0.6591\t\taverage: 0.6172\t\tstd: 0.0295\n",
      "\n",
      "model 1/10 - generation 9/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.6490 - acc: 0.4160 - val_loss: 1.3883 - val_acc: 0.5120\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2615 - acc: 0.5552 - val_loss: 1.1953 - val_acc: 0.5838\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1034 - acc: 0.6152 - val_loss: 1.1515 - val_acc: 0.5995\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0179 - acc: 0.6457 - val_loss: 1.1616 - val_acc: 0.5956\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9623 - acc: 0.6666 - val_loss: 1.1383 - val_acc: 0.6003\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9277 - acc: 0.6765 - val_loss: 1.1598 - val_acc: 0.5985\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8934 - acc: 0.6895 - val_loss: 1.0645 - val_acc: 0.6292\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8620 - acc: 0.7001 - val_loss: 1.0886 - val_acc: 0.6271\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8359 - acc: 0.7103 - val_loss: 1.0508 - val_acc: 0.6392\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8086 - acc: 0.7183 - val_loss: 1.0799 - val_acc: 0.6333\n",
      "\n",
      "model 2/10 - generation 9/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.6237 - acc: 0.4194 - val_loss: 1.4259 - val_acc: 0.4967\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3190 - acc: 0.5315 - val_loss: 1.2734 - val_acc: 0.5487\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2005 - acc: 0.5770 - val_loss: 1.2225 - val_acc: 0.5689\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1416 - acc: 0.5983 - val_loss: 1.1830 - val_acc: 0.5768\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0840 - acc: 0.6215 - val_loss: 1.1638 - val_acc: 0.5904\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0270 - acc: 0.6410 - val_loss: 1.1666 - val_acc: 0.5935\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9767 - acc: 0.6596 - val_loss: 1.1010 - val_acc: 0.6151\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9300 - acc: 0.6752 - val_loss: 1.0783 - val_acc: 0.6299\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8974 - acc: 0.6875 - val_loss: 1.0672 - val_acc: 0.6313\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8702 - acc: 0.6967 - val_loss: 1.0588 - val_acc: 0.6399\n",
      "\n",
      "model 3/10 - generation 9/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 27s - loss: 12.8722 - acc: 0.1952 - val_loss: 12.7055 - val_acc: 0.2044\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 25s - loss: 12.5478 - acc: 0.2122 - val_loss: 12.4194 - val_acc: 0.2163\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 25s - loss: 12.3006 - acc: 0.2198 - val_loss: 12.2580 - val_acc: 0.2187\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 25s - loss: 12.0485 - acc: 0.2274 - val_loss: 11.9820 - val_acc: 0.2271\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 25s - loss: 11.8410 - acc: 0.2335 - val_loss: 11.8679 - val_acc: 0.2301\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 25s - loss: 11.7059 - acc: 0.2377 - val_loss: 11.6819 - val_acc: 0.2363\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 25s - loss: 11.6190 - acc: 0.2406 - val_loss: 11.5823 - val_acc: 0.2405\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 25s - loss: 11.5652 - acc: 0.2457 - val_loss: 11.5511 - val_acc: 0.2407\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 25s - loss: 11.5328 - acc: 0.2466 - val_loss: 11.5404 - val_acc: 0.2430\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 25s - loss: 11.5017 - acc: 0.2498 - val_loss: 11.5273 - val_acc: 0.2431\n",
      "\n",
      "model 4/10 - generation 9/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 14.5001 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "model 5/10 - generation 9/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.6961 - acc: 0.3911 - val_loss: 1.7520 - val_acc: 0.3873\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3061 - acc: 0.5391 - val_loss: 1.2844 - val_acc: 0.5436\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1814 - acc: 0.5833 - val_loss: 1.2355 - val_acc: 0.5663\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1035 - acc: 0.6138 - val_loss: 1.1738 - val_acc: 0.5933\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0441 - acc: 0.6334 - val_loss: 1.1598 - val_acc: 0.5926\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9948 - acc: 0.6514 - val_loss: 1.0871 - val_acc: 0.6189\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9556 - acc: 0.6636 - val_loss: 1.1065 - val_acc: 0.6135\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9274 - acc: 0.6752 - val_loss: 1.1363 - val_acc: 0.6033\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 6/10 - generation 9/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.6315 - acc: 0.4121 - val_loss: 1.4886 - val_acc: 0.4873\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.3510 - acc: 0.5185 - val_loss: 1.3174 - val_acc: 0.5388\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2572 - acc: 0.5538 - val_loss: 1.3320 - val_acc: 0.5327\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2003 - acc: 0.5737 - val_loss: 1.2706 - val_acc: 0.5628\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1646 - acc: 0.5878 - val_loss: 1.2076 - val_acc: 0.5845\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1232 - acc: 0.6069 - val_loss: 1.2328 - val_acc: 0.5690\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0936 - acc: 0.6185 - val_loss: 1.1894 - val_acc: 0.5918\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0590 - acc: 0.6281 - val_loss: 1.1229 - val_acc: 0.6120\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0344 - acc: 0.6380 - val_loss: 1.1573 - val_acc: 0.6007\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0193 - acc: 0.6430 - val_loss: 1.1194 - val_acc: 0.6106\n",
      "\n",
      "model 7/10 - generation 9/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.6823 - acc: 0.3916 - val_loss: 1.4102 - val_acc: 0.5040\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2744 - acc: 0.5502 - val_loss: 1.4737 - val_acc: 0.4804\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1552 - acc: 0.5977 - val_loss: 1.1829 - val_acc: 0.5895\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0810 - acc: 0.6242 - val_loss: 1.1757 - val_acc: 0.5943\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0209 - acc: 0.6431 - val_loss: 1.1340 - val_acc: 0.6018\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9771 - acc: 0.6587 - val_loss: 1.0753 - val_acc: 0.6276\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9340 - acc: 0.6743 - val_loss: 1.1053 - val_acc: 0.6190\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8984 - acc: 0.6875 - val_loss: 1.0606 - val_acc: 0.6361\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8719 - acc: 0.6959 - val_loss: 1.0592 - val_acc: 0.6358\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8448 - acc: 0.7052 - val_loss: 1.0928 - val_acc: 0.6233\n",
      "\n",
      "model 8/10 - generation 9/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.6574 - acc: 0.4113 - val_loss: 1.5863 - val_acc: 0.4485\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2881 - acc: 0.5443 - val_loss: 1.2949 - val_acc: 0.5573\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1838 - acc: 0.5833 - val_loss: 1.2123 - val_acc: 0.5812\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1211 - acc: 0.6066 - val_loss: 1.1571 - val_acc: 0.6018\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0760 - acc: 0.6232 - val_loss: 1.1347 - val_acc: 0.6100\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0422 - acc: 0.6335 - val_loss: 1.2154 - val_acc: 0.5818\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0114 - acc: 0.6458 - val_loss: 1.0840 - val_acc: 0.6284\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9878 - acc: 0.6561 - val_loss: 1.0783 - val_acc: 0.6254\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9684 - acc: 0.6615 - val_loss: 1.0441 - val_acc: 0.6408\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9522 - acc: 0.6684 - val_loss: 1.0628 - val_acc: 0.6377\n",
      "\n",
      "model 9/10 - generation 9/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.7739 - acc: 0.3609 - val_loss: 1.4411 - val_acc: 0.4895\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.3511 - acc: 0.5209 - val_loss: 1.2788 - val_acc: 0.5462\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2375 - acc: 0.5630 - val_loss: 1.3420 - val_acc: 0.5364\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1758 - acc: 0.5853 - val_loss: 1.1726 - val_acc: 0.5838\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1179 - acc: 0.6089 - val_loss: 1.1401 - val_acc: 0.6001\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0801 - acc: 0.6227 - val_loss: 1.1056 - val_acc: 0.6106\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0462 - acc: 0.6346 - val_loss: 1.1071 - val_acc: 0.6074\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0164 - acc: 0.6438 - val_loss: 1.0781 - val_acc: 0.6229\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9974 - acc: 0.6505 - val_loss: 1.0634 - val_acc: 0.6270\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9759 - acc: 0.6598 - val_loss: 1.0579 - val_acc: 0.6299\n",
      "\n",
      "model 10/10 - generation 9/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.7222 - acc: 0.3794 - val_loss: 1.6637 - val_acc: 0.3908\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3690 - acc: 0.5128 - val_loss: 1.3069 - val_acc: 0.5305\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2086 - acc: 0.5732 - val_loss: 1.4583 - val_acc: 0.5192\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1149 - acc: 0.6109 - val_loss: 1.2566 - val_acc: 0.5651\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0394 - acc: 0.6365 - val_loss: 1.1191 - val_acc: 0.6057\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9911 - acc: 0.6551 - val_loss: 1.1043 - val_acc: 0.6091\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9465 - acc: 0.6715 - val_loss: 1.1045 - val_acc: 0.6159\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9169 - acc: 0.6804 - val_loss: 1.0827 - val_acc: 0.6273\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8801 - acc: 0.6926 - val_loss: 1.0480 - val_acc: 0.6373\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8602 - acc: 0.6988 - val_loss: 1.0315 - val_acc: 0.6439\n",
      "Generation 9:\t\tbest accuracy: 0.6439\t\taverage: 0.5365\t\tstd: 0.1857\n",
      "\n",
      "model 1/10 - generation 10/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.7255 - acc: 0.3802 - val_loss: 1.5539 - val_acc: 0.4372\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.4781 - acc: 0.4704 - val_loss: 1.4329 - val_acc: 0.4855\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3384 - acc: 0.5238 - val_loss: 1.2818 - val_acc: 0.5478\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2067 - acc: 0.5768 - val_loss: 1.2389 - val_acc: 0.5632\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1339 - acc: 0.6003 - val_loss: 1.1802 - val_acc: 0.5818\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0868 - acc: 0.6213 - val_loss: 1.1518 - val_acc: 0.5992\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0397 - acc: 0.6373 - val_loss: 1.1034 - val_acc: 0.6156\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0020 - acc: 0.6514 - val_loss: 1.1184 - val_acc: 0.6135\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9669 - acc: 0.6635 - val_loss: 1.1422 - val_acc: 0.6038\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 2/10 - generation 10/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.6944 - acc: 0.3997 - val_loss: 1.4725 - val_acc: 0.4774\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3760 - acc: 0.5084 - val_loss: 1.3341 - val_acc: 0.5242\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2680 - acc: 0.5501 - val_loss: 1.2389 - val_acc: 0.5611\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1743 - acc: 0.5859 - val_loss: 1.1842 - val_acc: 0.5796\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1124 - acc: 0.6060 - val_loss: 1.1713 - val_acc: 0.5874\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0580 - acc: 0.6297 - val_loss: 1.1993 - val_acc: 0.5825\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0118 - acc: 0.6449 - val_loss: 1.0834 - val_acc: 0.6261\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9654 - acc: 0.6629 - val_loss: 1.0502 - val_acc: 0.6309\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9220 - acc: 0.6790 - val_loss: 1.0634 - val_acc: 0.6322\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8922 - acc: 0.6882 - val_loss: 1.0503 - val_acc: 0.6371\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "model 3/10 - generation 10/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.7498 - acc: 0.4263 - val_loss: 1.4653 - val_acc: 0.4780\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2723 - acc: 0.5523 - val_loss: 1.2761 - val_acc: 0.5427\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1619 - acc: 0.5923 - val_loss: 1.1953 - val_acc: 0.5746\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0862 - acc: 0.6193 - val_loss: 1.2030 - val_acc: 0.5766\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 17s - loss: 1.0339 - acc: 0.6377 - val_loss: 1.1572 - val_acc: 0.5972\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9796 - acc: 0.6576 - val_loss: 1.1095 - val_acc: 0.6153\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9351 - acc: 0.6750 - val_loss: 1.0869 - val_acc: 0.6277\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8935 - acc: 0.6884 - val_loss: 1.0777 - val_acc: 0.6301\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8616 - acc: 0.6991 - val_loss: 1.0648 - val_acc: 0.6380\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8245 - acc: 0.7120 - val_loss: 1.0751 - val_acc: 0.6369\n",
      "\n",
      "model 4/10 - generation 10/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.8088 - acc: 0.3416 - val_loss: 1.5232 - val_acc: 0.4592\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.4249 - acc: 0.4902 - val_loss: 1.3452 - val_acc: 0.5170\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2901 - acc: 0.5434 - val_loss: 1.2489 - val_acc: 0.5580\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1984 - acc: 0.5786 - val_loss: 1.1963 - val_acc: 0.5794\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1270 - acc: 0.6077 - val_loss: 1.1798 - val_acc: 0.5841\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0750 - acc: 0.6225 - val_loss: 1.1251 - val_acc: 0.6037\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0194 - acc: 0.6423 - val_loss: 1.0957 - val_acc: 0.6182\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9682 - acc: 0.6620 - val_loss: 1.1002 - val_acc: 0.6168\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9225 - acc: 0.6772 - val_loss: 1.0538 - val_acc: 0.6328\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8867 - acc: 0.6914 - val_loss: 1.0889 - val_acc: 0.6223\n",
      "\n",
      "model 5/10 - generation 10/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.7295 - acc: 0.3805 - val_loss: 1.4230 - val_acc: 0.4947\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3275 - acc: 0.5310 - val_loss: 1.2532 - val_acc: 0.5572\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1806 - acc: 0.5863 - val_loss: 1.2013 - val_acc: 0.5804\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0892 - acc: 0.6192 - val_loss: 1.2045 - val_acc: 0.5727\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0232 - acc: 0.6420 - val_loss: 1.1456 - val_acc: 0.6030\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9712 - acc: 0.6609 - val_loss: 1.1151 - val_acc: 0.6150\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9325 - acc: 0.6739 - val_loss: 1.0747 - val_acc: 0.6319\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8958 - acc: 0.6881 - val_loss: 1.0608 - val_acc: 0.6336\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8713 - acc: 0.6967 - val_loss: 1.0615 - val_acc: 0.6329\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8472 - acc: 0.7026 - val_loss: 1.0434 - val_acc: 0.6443\n",
      "\n",
      "model 6/10 - generation 10/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6562 - acc: 0.4046 - val_loss: 1.3710 - val_acc: 0.5104\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3118 - acc: 0.5351 - val_loss: 1.2832 - val_acc: 0.5472\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1761 - acc: 0.5867 - val_loss: 1.1871 - val_acc: 0.5889\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0901 - acc: 0.6182 - val_loss: 1.1996 - val_acc: 0.5830\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0234 - acc: 0.6400 - val_loss: 1.0994 - val_acc: 0.6139\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9805 - acc: 0.6572 - val_loss: 1.1118 - val_acc: 0.6116\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9408 - acc: 0.6718 - val_loss: 1.0687 - val_acc: 0.6304\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9125 - acc: 0.6807 - val_loss: 1.0635 - val_acc: 0.6329\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8773 - acc: 0.6929 - val_loss: 1.0331 - val_acc: 0.6394\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8462 - acc: 0.7042 - val_loss: 1.0315 - val_acc: 0.6431\n",
      "\n",
      "model 7/10 - generation 10/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.6611 - acc: 0.4036 - val_loss: 1.4908 - val_acc: 0.4862\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.3085 - acc: 0.5336 - val_loss: 1.2877 - val_acc: 0.5634\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2025 - acc: 0.5748 - val_loss: 1.2253 - val_acc: 0.5823\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1152 - acc: 0.6082 - val_loss: 1.2951 - val_acc: 0.5370\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0628 - acc: 0.6291 - val_loss: 1.1222 - val_acc: 0.6201\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0251 - acc: 0.6423 - val_loss: 1.0848 - val_acc: 0.6340\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9987 - acc: 0.6511 - val_loss: 1.0657 - val_acc: 0.6449\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9706 - acc: 0.6611 - val_loss: 1.0333 - val_acc: 0.6453\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9543 - acc: 0.6681 - val_loss: 1.0300 - val_acc: 0.6494\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9377 - acc: 0.6741 - val_loss: 1.0509 - val_acc: 0.6445\n",
      "\n",
      "model 8/10 - generation 10/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.6620 - acc: 0.4109 - val_loss: 1.4139 - val_acc: 0.4923\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3284 - acc: 0.5317 - val_loss: 1.3007 - val_acc: 0.5331\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2019 - acc: 0.5774 - val_loss: 1.2529 - val_acc: 0.5583\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1334 - acc: 0.6007 - val_loss: 1.1600 - val_acc: 0.5861\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0823 - acc: 0.6200 - val_loss: 1.1478 - val_acc: 0.5910\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0401 - acc: 0.6360 - val_loss: 1.0979 - val_acc: 0.6122\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9989 - acc: 0.6528 - val_loss: 1.1110 - val_acc: 0.6100\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9621 - acc: 0.6646 - val_loss: 1.0806 - val_acc: 0.6199\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9303 - acc: 0.6763 - val_loss: 1.0750 - val_acc: 0.6257\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9019 - acc: 0.6869 - val_loss: 1.0525 - val_acc: 0.6367\n",
      "\n",
      "model 9/10 - generation 10/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.7197 - acc: 0.3821 - val_loss: 1.4625 - val_acc: 0.4781\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.3727 - acc: 0.5144 - val_loss: 1.2929 - val_acc: 0.5371\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2351 - acc: 0.5653 - val_loss: 1.2015 - val_acc: 0.5785\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1603 - acc: 0.5951 - val_loss: 1.1751 - val_acc: 0.5870\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1048 - acc: 0.6136 - val_loss: 1.1420 - val_acc: 0.5937\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0592 - acc: 0.6291 - val_loss: 1.1000 - val_acc: 0.6143\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0226 - acc: 0.6416 - val_loss: 1.0810 - val_acc: 0.6215\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9913 - acc: 0.6540 - val_loss: 1.0586 - val_acc: 0.6271\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9660 - acc: 0.6602 - val_loss: 1.0522 - val_acc: 0.6306\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9397 - acc: 0.6721 - val_loss: 1.0398 - val_acc: 0.6389\n",
      "\n",
      "model 10/10 - generation 10/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6755 - acc: 0.4012 - val_loss: 2.0171 - val_acc: 0.3921\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3512 - acc: 0.5182 - val_loss: 1.4242 - val_acc: 0.4869\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2285 - acc: 0.5663 - val_loss: 1.2494 - val_acc: 0.5578\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1566 - acc: 0.5900 - val_loss: 1.1976 - val_acc: 0.5737\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1008 - acc: 0.6118 - val_loss: 1.1829 - val_acc: 0.5809\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0515 - acc: 0.6287 - val_loss: 1.1518 - val_acc: 0.5910\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0038 - acc: 0.6486 - val_loss: 1.1821 - val_acc: 0.5900\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9684 - acc: 0.6601 - val_loss: 1.1123 - val_acc: 0.6132\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9325 - acc: 0.6733 - val_loss: 1.1284 - val_acc: 0.6079\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9043 - acc: 0.6820 - val_loss: 1.2061 - val_acc: 0.5898\n",
      "Epoch 00009: early stopping\n",
      "Generation 10:\t\tbest accuracy: 0.6445\t\taverage: 0.6297\t\tstd: 0.0178\n",
      "\n",
      "model 1/10 - generation 11/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.7082 - acc: 0.3904 - val_loss: 1.4759 - val_acc: 0.4723\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3697 - acc: 0.5165 - val_loss: 1.3240 - val_acc: 0.5274\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2311 - acc: 0.5681 - val_loss: 1.3446 - val_acc: 0.5293\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1424 - acc: 0.6017 - val_loss: 1.1878 - val_acc: 0.5820\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0678 - acc: 0.6282 - val_loss: 1.1700 - val_acc: 0.5941\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0102 - acc: 0.6470 - val_loss: 1.2359 - val_acc: 0.5748\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9595 - acc: 0.6662 - val_loss: 1.1349 - val_acc: 0.6055\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9109 - acc: 0.6827 - val_loss: 1.1492 - val_acc: 0.6098\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8733 - acc: 0.6956 - val_loss: 1.1253 - val_acc: 0.6161\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8412 - acc: 0.7064 - val_loss: 1.1183 - val_acc: 0.6178\n",
      "\n",
      "model 2/10 - generation 11/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.7702 - acc: 0.3624 - val_loss: 1.5994 - val_acc: 0.4544\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3588 - acc: 0.5136 - val_loss: 1.2891 - val_acc: 0.5443\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2401 - acc: 0.5598 - val_loss: 1.2680 - val_acc: 0.5583\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1498 - acc: 0.5952 - val_loss: 1.1846 - val_acc: 0.5855\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0727 - acc: 0.6231 - val_loss: 1.1045 - val_acc: 0.6185\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0114 - acc: 0.6463 - val_loss: 1.0938 - val_acc: 0.6192\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9665 - acc: 0.6643 - val_loss: 1.0622 - val_acc: 0.6341\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9360 - acc: 0.6728 - val_loss: 1.0529 - val_acc: 0.6353\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9025 - acc: 0.6884 - val_loss: 1.0352 - val_acc: 0.6440\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8752 - acc: 0.6940 - val_loss: 1.0469 - val_acc: 0.6365\n",
      "\n",
      "model 3/10 - generation 11/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.7982 - acc: 0.3579 - val_loss: 1.6767 - val_acc: 0.4122\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.4557 - acc: 0.4814 - val_loss: 1.4572 - val_acc: 0.4917\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.3246 - acc: 0.5315 - val_loss: 1.3414 - val_acc: 0.5346\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2458 - acc: 0.5594 - val_loss: 1.3006 - val_acc: 0.5540\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1892 - acc: 0.5808 - val_loss: 1.2811 - val_acc: 0.5417\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1397 - acc: 0.5999 - val_loss: 1.1859 - val_acc: 0.5901\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1055 - acc: 0.6126 - val_loss: 1.1708 - val_acc: 0.5954\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0791 - acc: 0.6219 - val_loss: 1.1395 - val_acc: 0.6037\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0530 - acc: 0.6291 - val_loss: 1.1384 - val_acc: 0.5999\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0311 - acc: 0.6374 - val_loss: 1.1435 - val_acc: 0.6032\n",
      "\n",
      "model 4/10 - generation 11/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.7012 - acc: 0.3946 - val_loss: 1.4499 - val_acc: 0.4834\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3652 - acc: 0.5167 - val_loss: 1.3166 - val_acc: 0.5354\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2080 - acc: 0.5761 - val_loss: 1.2186 - val_acc: 0.5732\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1092 - acc: 0.6104 - val_loss: 1.1445 - val_acc: 0.6010\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0364 - acc: 0.6398 - val_loss: 1.1277 - val_acc: 0.6100\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9773 - acc: 0.6593 - val_loss: 1.0984 - val_acc: 0.6170\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9304 - acc: 0.6751 - val_loss: 1.0670 - val_acc: 0.6318\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8974 - acc: 0.6864 - val_loss: 1.0773 - val_acc: 0.6314\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8668 - acc: 0.6983 - val_loss: 1.0570 - val_acc: 0.6336\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8375 - acc: 0.7100 - val_loss: 1.0488 - val_acc: 0.6422\n",
      "\n",
      "model 5/10 - generation 11/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 14.4988 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "model 6/10 - generation 11/20:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.6585 - acc: 0.4063 - val_loss: 1.3974 - val_acc: 0.4966\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3415 - acc: 0.5264 - val_loss: 1.3087 - val_acc: 0.5346\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2136 - acc: 0.5730 - val_loss: 1.2008 - val_acc: 0.5721\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1236 - acc: 0.6043 - val_loss: 1.1740 - val_acc: 0.5883\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0633 - acc: 0.6286 - val_loss: 1.1281 - val_acc: 0.6011\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0136 - acc: 0.6454 - val_loss: 1.1775 - val_acc: 0.5908\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9769 - acc: 0.6587 - val_loss: 1.1026 - val_acc: 0.6117\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9456 - acc: 0.6672 - val_loss: 1.0915 - val_acc: 0.6188\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9209 - acc: 0.6786 - val_loss: 1.0749 - val_acc: 0.6268\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9005 - acc: 0.6848 - val_loss: 1.0728 - val_acc: 0.6283\n",
      "\n",
      "model 7/10 - generation 11/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.5751 - acc: 0.4372 - val_loss: 1.4565 - val_acc: 0.4980\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2854 - acc: 0.5462 - val_loss: 1.2886 - val_acc: 0.5597\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1835 - acc: 0.5844 - val_loss: 1.1947 - val_acc: 0.5950\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1163 - acc: 0.6105 - val_loss: 1.1598 - val_acc: 0.6051\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0633 - acc: 0.6275 - val_loss: 1.0993 - val_acc: 0.6235\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0196 - acc: 0.6449 - val_loss: 1.0762 - val_acc: 0.6283\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9858 - acc: 0.6564 - val_loss: 1.0591 - val_acc: 0.6388\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9573 - acc: 0.6667 - val_loss: 1.0532 - val_acc: 0.6434\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9361 - acc: 0.6754 - val_loss: 1.0329 - val_acc: 0.6449\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9189 - acc: 0.6806 - val_loss: 1.0370 - val_acc: 0.6379\n",
      "\n",
      "model 8/10 - generation 11/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.7827 - acc: 0.3694 - val_loss: 1.5021 - val_acc: 0.4640\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3379 - acc: 0.5284 - val_loss: 1.2960 - val_acc: 0.5431\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2126 - acc: 0.5725 - val_loss: 1.3414 - val_acc: 0.5294\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1419 - acc: 0.6016 - val_loss: 1.2425 - val_acc: 0.5678\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0702 - acc: 0.6255 - val_loss: 1.1487 - val_acc: 0.6004\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0168 - acc: 0.6477 - val_loss: 1.1273 - val_acc: 0.6111\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9737 - acc: 0.6618 - val_loss: 1.0890 - val_acc: 0.6173\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9367 - acc: 0.6736 - val_loss: 1.0747 - val_acc: 0.6248\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9013 - acc: 0.6845 - val_loss: 1.1063 - val_acc: 0.6171\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8742 - acc: 0.6934 - val_loss: 1.1037 - val_acc: 0.6227\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "model 9/10 - generation 11/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.9792 - acc: 0.3783 - val_loss: 1.4875 - val_acc: 0.4639\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3824 - acc: 0.5078 - val_loss: 1.3747 - val_acc: 0.5133\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2580 - acc: 0.5539 - val_loss: 1.2413 - val_acc: 0.5613\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1586 - acc: 0.5908 - val_loss: 1.2081 - val_acc: 0.5737\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0873 - acc: 0.6197 - val_loss: 1.2119 - val_acc: 0.5801\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0348 - acc: 0.6388 - val_loss: 1.1841 - val_acc: 0.5892\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9929 - acc: 0.6514 - val_loss: 1.1090 - val_acc: 0.6132\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9571 - acc: 0.6666 - val_loss: 1.0827 - val_acc: 0.6235\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9253 - acc: 0.6785 - val_loss: 1.0929 - val_acc: 0.6202\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8996 - acc: 0.6884 - val_loss: 1.0784 - val_acc: 0.6268\n",
      "\n",
      "model 10/10 - generation 11/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6030 - acc: 0.4297 - val_loss: 1.3601 - val_acc: 0.5165\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2634 - acc: 0.5535 - val_loss: 1.2374 - val_acc: 0.5684\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1303 - acc: 0.6016 - val_loss: 1.1535 - val_acc: 0.5994\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0518 - acc: 0.6311 - val_loss: 1.1270 - val_acc: 0.6095\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9961 - acc: 0.6500 - val_loss: 1.1398 - val_acc: 0.6065\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9516 - acc: 0.6676 - val_loss: 1.0915 - val_acc: 0.6209\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9077 - acc: 0.6831 - val_loss: 1.0616 - val_acc: 0.6376\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8719 - acc: 0.6971 - val_loss: 1.0655 - val_acc: 0.6357\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8429 - acc: 0.7060 - val_loss: 1.0569 - val_acc: 0.6388\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8199 - acc: 0.7133 - val_loss: 1.0642 - val_acc: 0.6404\n",
      "Generation 11:\t\tbest accuracy: 0.6422\t\taverage: 0.5756\t\tstd: 0.1589\n",
      "\n",
      "model 1/10 - generation 12/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.5496 - acc: 0.4462 - val_loss: 1.4596 - val_acc: 0.4856\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2871 - acc: 0.5454 - val_loss: 1.3216 - val_acc: 0.5405\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1993 - acc: 0.5759 - val_loss: 1.2234 - val_acc: 0.5707\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1209 - acc: 0.6094 - val_loss: 1.1708 - val_acc: 0.5953\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0707 - acc: 0.6276 - val_loss: 1.1070 - val_acc: 0.6222\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0285 - acc: 0.6432 - val_loss: 1.1285 - val_acc: 0.6095\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0027 - acc: 0.6546 - val_loss: 1.0683 - val_acc: 0.6294\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9787 - acc: 0.6612 - val_loss: 1.0888 - val_acc: 0.6220\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9615 - acc: 0.6656 - val_loss: 1.0368 - val_acc: 0.6469\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9456 - acc: 0.6729 - val_loss: 1.0946 - val_acc: 0.6195\n",
      "\n",
      "model 2/10 - generation 12/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6763 - acc: 0.3992 - val_loss: 1.4548 - val_acc: 0.4796\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3968 - acc: 0.5024 - val_loss: 1.3869 - val_acc: 0.4996\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2836 - acc: 0.5484 - val_loss: 1.2782 - val_acc: 0.5423\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2063 - acc: 0.5749 - val_loss: 1.2434 - val_acc: 0.5588\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1350 - acc: 0.5992 - val_loss: 1.1774 - val_acc: 0.5802\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0791 - acc: 0.6207 - val_loss: 1.1634 - val_acc: 0.5921\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0277 - acc: 0.6417 - val_loss: 1.1218 - val_acc: 0.6062\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9879 - acc: 0.6556 - val_loss: 1.1068 - val_acc: 0.6117\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9513 - acc: 0.6667 - val_loss: 1.0820 - val_acc: 0.6251\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9153 - acc: 0.6834 - val_loss: 1.0739 - val_acc: 0.6262\n",
      "\n",
      "model 3/10 - generation 12/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.7904 - acc: 0.3575 - val_loss: 1.5189 - val_acc: 0.4612\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3830 - acc: 0.5053 - val_loss: 1.3316 - val_acc: 0.5216\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2591 - acc: 0.5528 - val_loss: 1.2410 - val_acc: 0.5516\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1865 - acc: 0.5812 - val_loss: 1.2200 - val_acc: 0.5650\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1184 - acc: 0.6067 - val_loss: 1.1532 - val_acc: 0.5863\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0617 - acc: 0.6268 - val_loss: 1.1399 - val_acc: 0.5957\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0151 - acc: 0.6441 - val_loss: 1.1017 - val_acc: 0.6122\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9775 - acc: 0.6562 - val_loss: 1.1210 - val_acc: 0.6073\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9475 - acc: 0.6694 - val_loss: 1.1017 - val_acc: 0.6154\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 4/10 - generation 12/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6457 - acc: 0.4127 - val_loss: 1.3652 - val_acc: 0.5192\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2602 - acc: 0.5565 - val_loss: 1.2230 - val_acc: 0.5693\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1449 - acc: 0.5981 - val_loss: 1.2086 - val_acc: 0.5789\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0718 - acc: 0.6232 - val_loss: 1.1285 - val_acc: 0.5993\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0176 - acc: 0.6435 - val_loss: 1.0973 - val_acc: 0.6122\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9719 - acc: 0.6628 - val_loss: 1.0837 - val_acc: 0.6181\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9340 - acc: 0.6729 - val_loss: 1.0647 - val_acc: 0.6306\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9007 - acc: 0.6854 - val_loss: 1.0490 - val_acc: 0.6368\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8645 - acc: 0.6981 - val_loss: 1.0293 - val_acc: 0.6416\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8372 - acc: 0.7059 - val_loss: 1.0266 - val_acc: 0.6485\n",
      "\n",
      "model 5/10 - generation 12/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.8520 - acc: 0.4227 - val_loss: 1.3940 - val_acc: 0.5129\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2160 - acc: 0.5728 - val_loss: 1.2692 - val_acc: 0.5527\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0961 - acc: 0.6184 - val_loss: 1.2077 - val_acc: 0.5730\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0261 - acc: 0.6419 - val_loss: 1.2027 - val_acc: 0.5837\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9840 - acc: 0.6561 - val_loss: 1.1325 - val_acc: 0.6045\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9368 - acc: 0.6730 - val_loss: 1.1491 - val_acc: 0.6050\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8934 - acc: 0.6897 - val_loss: 1.1431 - val_acc: 0.6023\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 6/10 - generation 12/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6938 - acc: 0.3916 - val_loss: 1.5034 - val_acc: 0.4614\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3790 - acc: 0.5100 - val_loss: 1.3708 - val_acc: 0.5040\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2696 - acc: 0.5513 - val_loss: 1.2824 - val_acc: 0.5470\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1915 - acc: 0.5800 - val_loss: 1.2251 - val_acc: 0.5666\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1305 - acc: 0.6002 - val_loss: 1.2252 - val_acc: 0.5713\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0796 - acc: 0.6216 - val_loss: 1.2417 - val_acc: 0.5605\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "model 7/10 - generation 12/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6622 - acc: 0.4113 - val_loss: 1.3852 - val_acc: 0.5190\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3051 - acc: 0.5405 - val_loss: 1.2695 - val_acc: 0.5576\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1955 - acc: 0.5789 - val_loss: 1.1846 - val_acc: 0.5840\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1292 - acc: 0.6037 - val_loss: 1.1978 - val_acc: 0.5837\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0733 - acc: 0.6230 - val_loss: 1.1361 - val_acc: 0.6095\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0312 - acc: 0.6386 - val_loss: 1.1456 - val_acc: 0.6017\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9887 - acc: 0.6539 - val_loss: 1.1114 - val_acc: 0.6171\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9495 - acc: 0.6681 - val_loss: 1.0782 - val_acc: 0.6297\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9142 - acc: 0.6832 - val_loss: 1.0720 - val_acc: 0.6344\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8850 - acc: 0.6879 - val_loss: 1.0614 - val_acc: 0.6347\n",
      "\n",
      "model 8/10 - generation 12/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6319 - acc: 0.4174 - val_loss: 1.3944 - val_acc: 0.5034\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2646 - acc: 0.5549 - val_loss: 1.2531 - val_acc: 0.5564\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1280 - acc: 0.6063 - val_loss: 1.1907 - val_acc: 0.5798\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0456 - acc: 0.6355 - val_loss: 1.1541 - val_acc: 0.5979\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9835 - acc: 0.6588 - val_loss: 1.1214 - val_acc: 0.6165\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 17s - loss: 0.9320 - acc: 0.6759 - val_loss: 1.1088 - val_acc: 0.6207\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8873 - acc: 0.6939 - val_loss: 1.1123 - val_acc: 0.6145\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8475 - acc: 0.7063 - val_loss: 1.1155 - val_acc: 0.6210\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 9/10 - generation 12/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.6764 - acc: 0.4009 - val_loss: 1.5457 - val_acc: 0.4422\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.3897 - acc: 0.5047 - val_loss: 1.4160 - val_acc: 0.5113\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2620 - acc: 0.5553 - val_loss: 1.3350 - val_acc: 0.5326\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1666 - acc: 0.5926 - val_loss: 1.1837 - val_acc: 0.5968\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1135 - acc: 0.6119 - val_loss: 1.1636 - val_acc: 0.5944\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0753 - acc: 0.6286 - val_loss: 1.1446 - val_acc: 0.6084\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0492 - acc: 0.6372 - val_loss: 1.1383 - val_acc: 0.6034\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0223 - acc: 0.6440 - val_loss: 1.0920 - val_acc: 0.6316\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0047 - acc: 0.6522 - val_loss: 1.0978 - val_acc: 0.6289\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9877 - acc: 0.6580 - val_loss: 1.1294 - val_acc: 0.6053\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "model 10/10 - generation 12/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6226 - acc: 0.4191 - val_loss: 1.4899 - val_acc: 0.4732\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2408 - acc: 0.5630 - val_loss: 1.2453 - val_acc: 0.5627\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0903 - acc: 0.6196 - val_loss: 1.2007 - val_acc: 0.5835\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9988 - acc: 0.6542 - val_loss: 1.1759 - val_acc: 0.5915\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9314 - acc: 0.6778 - val_loss: 1.1714 - val_acc: 0.5888\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8777 - acc: 0.6952 - val_loss: 1.1507 - val_acc: 0.6069\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8257 - acc: 0.7133 - val_loss: 1.1391 - val_acc: 0.6107\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.7859 - acc: 0.7288 - val_loss: 1.1312 - val_acc: 0.6184\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7496 - acc: 0.7417 - val_loss: 1.1425 - val_acc: 0.6159\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.7163 - acc: 0.7505 - val_loss: 1.1764 - val_acc: 0.6158\n",
      "Epoch 00009: early stopping\n",
      "Generation 12:\t\tbest accuracy: 0.6485\t\taverage: 0.6149\t\tstd: 0.0222\n",
      "\n",
      "model 1/10 - generation 13/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.7987 - acc: 0.3504 - val_loss: 1.5227 - val_acc: 0.4611\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.4288 - acc: 0.4936 - val_loss: 1.3845 - val_acc: 0.5062\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2721 - acc: 0.5489 - val_loss: 1.2658 - val_acc: 0.5479\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1791 - acc: 0.5837 - val_loss: 1.3169 - val_acc: 0.5446\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1081 - acc: 0.6106 - val_loss: 1.1869 - val_acc: 0.5861\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0512 - acc: 0.6304 - val_loss: 1.1693 - val_acc: 0.5881\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0045 - acc: 0.6468 - val_loss: 1.1401 - val_acc: 0.6014\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9593 - acc: 0.6642 - val_loss: 1.1326 - val_acc: 0.6037\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9189 - acc: 0.6783 - val_loss: 1.1108 - val_acc: 0.6135\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8828 - acc: 0.6916 - val_loss: 1.1074 - val_acc: 0.6131\n",
      "\n",
      "model 2/10 - generation 13/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.6929 - acc: 0.3901 - val_loss: 1.5884 - val_acc: 0.4407\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.4193 - acc: 0.4942 - val_loss: 1.3903 - val_acc: 0.5084\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.3292 - acc: 0.5282 - val_loss: 1.3856 - val_acc: 0.5127\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2703 - acc: 0.5479 - val_loss: 1.3268 - val_acc: 0.5421\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1961 - acc: 0.5779 - val_loss: 1.3180 - val_acc: 0.5476\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1355 - acc: 0.6013 - val_loss: 1.1924 - val_acc: 0.5854\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0916 - acc: 0.6179 - val_loss: 1.1801 - val_acc: 0.5848\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0543 - acc: 0.6324 - val_loss: 1.1914 - val_acc: 0.5731\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0142 - acc: 0.6462 - val_loss: 1.1371 - val_acc: 0.5998\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9890 - acc: 0.6561 - val_loss: 1.1404 - val_acc: 0.5926\n",
      "\n",
      "model 3/10 - generation 13/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6720 - acc: 0.3987 - val_loss: 1.4407 - val_acc: 0.4885\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.3396 - acc: 0.5239 - val_loss: 1.3018 - val_acc: 0.5386\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2254 - acc: 0.5681 - val_loss: 1.2585 - val_acc: 0.5572\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1289 - acc: 0.6051 - val_loss: 1.1851 - val_acc: 0.5871\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0519 - acc: 0.6349 - val_loss: 1.1227 - val_acc: 0.6076\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9928 - acc: 0.6541 - val_loss: 1.1487 - val_acc: 0.6018\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9465 - acc: 0.6709 - val_loss: 1.0742 - val_acc: 0.6274\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9111 - acc: 0.6829 - val_loss: 1.0717 - val_acc: 0.6292\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8787 - acc: 0.6961 - val_loss: 1.0973 - val_acc: 0.6224\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8549 - acc: 0.7038 - val_loss: 1.0509 - val_acc: 0.6405\n",
      "\n",
      "model 4/10 - generation 13/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.7395 - acc: 0.3812 - val_loss: 1.4822 - val_acc: 0.4636\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3953 - acc: 0.4991 - val_loss: 1.3698 - val_acc: 0.5117\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2704 - acc: 0.5471 - val_loss: 1.2435 - val_acc: 0.5523\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1643 - acc: 0.5872 - val_loss: 1.1801 - val_acc: 0.5804\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0645 - acc: 0.6244 - val_loss: 1.1432 - val_acc: 0.5939\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0016 - acc: 0.6493 - val_loss: 1.0884 - val_acc: 0.6213\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9614 - acc: 0.6630 - val_loss: 1.0889 - val_acc: 0.6211\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9327 - acc: 0.6742 - val_loss: 1.0673 - val_acc: 0.6259\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9111 - acc: 0.6830 - val_loss: 1.0739 - val_acc: 0.6268\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8836 - acc: 0.6909 - val_loss: 1.0630 - val_acc: 0.6333\n",
      "\n",
      "model 5/10 - generation 13/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6030 - acc: 0.4299 - val_loss: 1.3424 - val_acc: 0.5212\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2314 - acc: 0.5685 - val_loss: 1.2191 - val_acc: 0.5678\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0866 - acc: 0.6178 - val_loss: 1.2267 - val_acc: 0.5760\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9993 - acc: 0.6533 - val_loss: 1.1434 - val_acc: 0.5990\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9333 - acc: 0.6759 - val_loss: 1.1280 - val_acc: 0.6053\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8815 - acc: 0.6946 - val_loss: 1.1397 - val_acc: 0.6063\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8394 - acc: 0.7068 - val_loss: 1.1288 - val_acc: 0.6145\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 6/10 - generation 13/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.5687 - acc: 0.4469 - val_loss: 1.3373 - val_acc: 0.5249\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2377 - acc: 0.5622 - val_loss: 1.2238 - val_acc: 0.5751\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1190 - acc: 0.6058 - val_loss: 1.3768 - val_acc: 0.5300\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0375 - acc: 0.6364 - val_loss: 1.1098 - val_acc: 0.6148\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9821 - acc: 0.6578 - val_loss: 1.1595 - val_acc: 0.5982\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9373 - acc: 0.6733 - val_loss: 1.1130 - val_acc: 0.6104\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "model 7/10 - generation 13/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6175 - acc: 0.4264 - val_loss: 1.3188 - val_acc: 0.5256\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1977 - acc: 0.5808 - val_loss: 1.2489 - val_acc: 0.5618\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0826 - acc: 0.6195 - val_loss: 1.1650 - val_acc: 0.5923\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0073 - acc: 0.6481 - val_loss: 1.1480 - val_acc: 0.5909\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9502 - acc: 0.6679 - val_loss: 1.1317 - val_acc: 0.6042\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9047 - acc: 0.6853 - val_loss: 1.1444 - val_acc: 0.6017\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8561 - acc: 0.7025 - val_loss: 1.1082 - val_acc: 0.6166\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8061 - acc: 0.7185 - val_loss: 1.1332 - val_acc: 0.6131\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7725 - acc: 0.7287 - val_loss: 1.1148 - val_acc: 0.6156\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 8/10 - generation 13/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 28s - loss: 12.1299 - acc: 0.2316 - val_loss: 11.5290 - val_acc: 0.2673\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 25s - loss: 11.2836 - acc: 0.2772 - val_loss: 11.5330 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 25s - loss: 10.8697 - acc: 0.2940 - val_loss: 11.1970 - val_acc: 0.2681\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 25s - loss: 10.5413 - acc: 0.3064 - val_loss: 10.4255 - val_acc: 0.3073\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 25s - loss: 10.3166 - acc: 0.3150 - val_loss: 10.4747 - val_acc: 0.2998\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 25s - loss: 10.1882 - acc: 0.3198 - val_loss: 10.2793 - val_acc: 0.3066\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 25s - loss: 10.1027 - acc: 0.3244 - val_loss: 10.4571 - val_acc: 0.2859\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 25s - loss: 10.0350 - acc: 0.3284 - val_loss: 10.1227 - val_acc: 0.3168\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 25s - loss: 9.9918 - acc: 0.3326 - val_loss: 10.2277 - val_acc: 0.3019\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 25s - loss: 9.9604 - acc: 0.3341 - val_loss: 10.3906 - val_acc: 0.2791\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "model 9/10 - generation 13/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.6370 - acc: 0.4218 - val_loss: 1.4755 - val_acc: 0.4894\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.3239 - acc: 0.5373 - val_loss: 1.3393 - val_acc: 0.5404\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2314 - acc: 0.5675 - val_loss: 1.2545 - val_acc: 0.5695\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1792 - acc: 0.5868 - val_loss: 1.2211 - val_acc: 0.5762\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1273 - acc: 0.6051 - val_loss: 1.1772 - val_acc: 0.6037\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0721 - acc: 0.6247 - val_loss: 1.1360 - val_acc: 0.6082\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0213 - acc: 0.6435 - val_loss: 1.1525 - val_acc: 0.6002\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9939 - acc: 0.6552 - val_loss: 1.1056 - val_acc: 0.6131\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9632 - acc: 0.6662 - val_loss: 1.0496 - val_acc: 0.6443\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9415 - acc: 0.6719 - val_loss: 1.0563 - val_acc: 0.6375\n",
      "\n",
      "model 10/10 - generation 13/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.6129 - acc: 0.4256 - val_loss: 1.4203 - val_acc: 0.5207\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.3036 - acc: 0.5423 - val_loss: 1.3101 - val_acc: 0.5526\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.2169 - acc: 0.5728 - val_loss: 1.2596 - val_acc: 0.5663\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.1734 - acc: 0.5894 - val_loss: 1.2141 - val_acc: 0.5876\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.1429 - acc: 0.5983 - val_loss: 1.1973 - val_acc: 0.5942\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.1116 - acc: 0.6122 - val_loss: 1.1724 - val_acc: 0.6028\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.0913 - acc: 0.6200 - val_loss: 1.1603 - val_acc: 0.6032\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.0741 - acc: 0.6242 - val_loss: 1.1434 - val_acc: 0.6141\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.0548 - acc: 0.6301 - val_loss: 1.1395 - val_acc: 0.6144\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.0387 - acc: 0.6378 - val_loss: 1.1115 - val_acc: 0.6219\n",
      "Generation 13:\t\tbest accuracy: 0.6405\t\taverage: 0.5858\t\tstd: 0.1031\n",
      "\n",
      "model 1/10 - generation 14/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 18s - loss: 1.6554 - acc: 0.4115 - val_loss: 1.4312 - val_acc: 0.5098\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.3046 - acc: 0.5402 - val_loss: 1.2687 - val_acc: 0.5615\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1528 - acc: 0.5954 - val_loss: 1.2058 - val_acc: 0.5958\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0593 - acc: 0.6313 - val_loss: 1.1135 - val_acc: 0.6146\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0109 - acc: 0.6483 - val_loss: 1.0326 - val_acc: 0.6477\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9793 - acc: 0.6606 - val_loss: 1.0786 - val_acc: 0.6385\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9621 - acc: 0.6658 - val_loss: 1.0684 - val_acc: 0.6343\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 2/10 - generation 14/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6774 - acc: 0.4058 - val_loss: 1.4356 - val_acc: 0.5011\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2896 - acc: 0.5468 - val_loss: 1.3194 - val_acc: 0.5387\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1620 - acc: 0.5925 - val_loss: 1.1655 - val_acc: 0.5909\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0691 - acc: 0.6248 - val_loss: 1.1447 - val_acc: 0.6011\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0086 - acc: 0.6496 - val_loss: 1.1209 - val_acc: 0.6109\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9625 - acc: 0.6631 - val_loss: 1.0945 - val_acc: 0.6133\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9273 - acc: 0.6770 - val_loss: 1.1011 - val_acc: 0.6188\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8914 - acc: 0.6897 - val_loss: 1.1136 - val_acc: 0.6127\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 3/10 - generation 14/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6494 - acc: 0.4052 - val_loss: 1.4115 - val_acc: 0.5025\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.3225 - acc: 0.5320 - val_loss: 1.2901 - val_acc: 0.5477\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2103 - acc: 0.5764 - val_loss: 1.2425 - val_acc: 0.5674\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1552 - acc: 0.5953 - val_loss: 1.1773 - val_acc: 0.5866\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0998 - acc: 0.6138 - val_loss: 1.2023 - val_acc: 0.5808\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0541 - acc: 0.6336 - val_loss: 1.1064 - val_acc: 0.6120\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0134 - acc: 0.6475 - val_loss: 1.1033 - val_acc: 0.6200\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9769 - acc: 0.6598 - val_loss: 1.0885 - val_acc: 0.6244\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9486 - acc: 0.6692 - val_loss: 1.1151 - val_acc: 0.6168\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9219 - acc: 0.6788 - val_loss: 1.0588 - val_acc: 0.6352\n",
      "\n",
      "model 4/10 - generation 14/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.5609 - acc: 0.4441 - val_loss: 1.4451 - val_acc: 0.4998\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2996 - acc: 0.5428 - val_loss: 1.3298 - val_acc: 0.5486\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2045 - acc: 0.5772 - val_loss: 1.2392 - val_acc: 0.5712\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1363 - acc: 0.6015 - val_loss: 1.1993 - val_acc: 0.5878\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0891 - acc: 0.6176 - val_loss: 1.2113 - val_acc: 0.5791\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0591 - acc: 0.6286 - val_loss: 1.1405 - val_acc: 0.6038\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0318 - acc: 0.6376 - val_loss: 1.1310 - val_acc: 0.6085\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0113 - acc: 0.6453 - val_loss: 1.1725 - val_acc: 0.5830\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9924 - acc: 0.6517 - val_loss: 1.1310 - val_acc: 0.5999\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9698 - acc: 0.6599 - val_loss: 1.0962 - val_acc: 0.6175\n",
      "\n",
      "model 5/10 - generation 14/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.7144 - acc: 0.3804 - val_loss: 1.5553 - val_acc: 0.4539\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.4437 - acc: 0.4808 - val_loss: 1.4042 - val_acc: 0.5101\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.3271 - acc: 0.5269 - val_loss: 1.3216 - val_acc: 0.5228\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2378 - acc: 0.5624 - val_loss: 1.2595 - val_acc: 0.5640\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1347 - acc: 0.6012 - val_loss: 1.1764 - val_acc: 0.5861\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0728 - acc: 0.6253 - val_loss: 1.1165 - val_acc: 0.6173\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0340 - acc: 0.6390 - val_loss: 1.1318 - val_acc: 0.6099\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0015 - acc: 0.6506 - val_loss: 1.0677 - val_acc: 0.6388\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9792 - acc: 0.6593 - val_loss: 1.0607 - val_acc: 0.6403\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9619 - acc: 0.6655 - val_loss: 1.0621 - val_acc: 0.6433\n",
      "\n",
      "model 6/10 - generation 14/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6593 - acc: 0.4062 - val_loss: 1.4914 - val_acc: 0.4662\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3863 - acc: 0.5064 - val_loss: 1.5107 - val_acc: 0.4587\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2681 - acc: 0.5525 - val_loss: 1.2947 - val_acc: 0.5364\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1842 - acc: 0.5859 - val_loss: 1.2286 - val_acc: 0.5725\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1076 - acc: 0.6146 - val_loss: 1.1707 - val_acc: 0.5835\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0365 - acc: 0.6409 - val_loss: 1.1633 - val_acc: 0.5878\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9801 - acc: 0.6582 - val_loss: 1.1046 - val_acc: 0.6110\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9410 - acc: 0.6756 - val_loss: 1.0875 - val_acc: 0.6281\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9076 - acc: 0.6834 - val_loss: 1.0737 - val_acc: 0.6310\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8849 - acc: 0.6905 - val_loss: 1.0589 - val_acc: 0.6373\n",
      "\n",
      "model 7/10 - generation 14/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.7133 - acc: 0.4093 - val_loss: 1.4177 - val_acc: 0.4886\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.3110 - acc: 0.5320 - val_loss: 1.2961 - val_acc: 0.5409\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1688 - acc: 0.5877 - val_loss: 1.1848 - val_acc: 0.5857\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0410 - acc: 0.6350 - val_loss: 1.1734 - val_acc: 0.5915\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9495 - acc: 0.6674 - val_loss: 1.0983 - val_acc: 0.6170\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8787 - acc: 0.6940 - val_loss: 1.1164 - val_acc: 0.6180\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8268 - acc: 0.7107 - val_loss: 1.1150 - val_acc: 0.6197\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 8/10 - generation 14/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.5729 - acc: 0.4422 - val_loss: 1.2879 - val_acc: 0.5434\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1945 - acc: 0.5814 - val_loss: 1.1977 - val_acc: 0.5751\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0655 - acc: 0.6293 - val_loss: 1.1416 - val_acc: 0.5990\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9656 - acc: 0.6655 - val_loss: 1.0966 - val_acc: 0.6210\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8886 - acc: 0.6909 - val_loss: 1.0703 - val_acc: 0.6294\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8351 - acc: 0.7108 - val_loss: 1.0817 - val_acc: 0.6296\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7933 - acc: 0.7259 - val_loss: 1.0965 - val_acc: 0.6334\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 9/10 - generation 14/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.6610 - acc: 0.4034 - val_loss: 1.4186 - val_acc: 0.4903\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2735 - acc: 0.5526 - val_loss: 1.2445 - val_acc: 0.5611\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0718 - acc: 0.6247 - val_loss: 1.2292 - val_acc: 0.5740\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9648 - acc: 0.6653 - val_loss: 1.1391 - val_acc: 0.6119\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9002 - acc: 0.6881 - val_loss: 1.1129 - val_acc: 0.6195\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8482 - acc: 0.7043 - val_loss: 1.1138 - val_acc: 0.6226\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8072 - acc: 0.7208 - val_loss: 1.0977 - val_acc: 0.6274\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7682 - acc: 0.7307 - val_loss: 1.0959 - val_acc: 0.6324\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7322 - acc: 0.7445 - val_loss: 1.1223 - val_acc: 0.6303\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7042 - acc: 0.7550 - val_loss: 1.1170 - val_acc: 0.6379\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "model 10/10 - generation 14/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.5931 - acc: 0.4301 - val_loss: 1.4455 - val_acc: 0.4878\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2194 - acc: 0.5678 - val_loss: 1.2652 - val_acc: 0.5498\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0845 - acc: 0.6207 - val_loss: 1.1660 - val_acc: 0.5927\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9850 - acc: 0.6543 - val_loss: 1.1366 - val_acc: 0.6025\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9177 - acc: 0.6806 - val_loss: 1.1179 - val_acc: 0.6141\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8688 - acc: 0.6983 - val_loss: 1.1047 - val_acc: 0.6206\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8300 - acc: 0.7122 - val_loss: 1.0872 - val_acc: 0.6278\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7872 - acc: 0.7253 - val_loss: 1.0876 - val_acc: 0.6337\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.7509 - acc: 0.7386 - val_loss: 1.0822 - val_acc: 0.6380\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7216 - acc: 0.7493 - val_loss: 1.0959 - val_acc: 0.6369\n",
      "Generation 14:\t\tbest accuracy: 0.6433\t\taverage: 0.6308\t\tstd: 0.0098\n",
      "\n",
      "model 1/10 - generation 15/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 2.3157 - acc: 0.4073 - val_loss: 1.3830 - val_acc: 0.4990\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.3162 - acc: 0.5345 - val_loss: 1.2046 - val_acc: 0.5730\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2176 - acc: 0.5699 - val_loss: 1.2470 - val_acc: 0.5577\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1493 - acc: 0.5966 - val_loss: 1.1824 - val_acc: 0.5823\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1011 - acc: 0.6133 - val_loss: 1.2737 - val_acc: 0.5586\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0595 - acc: 0.6272 - val_loss: 1.1182 - val_acc: 0.6069\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0287 - acc: 0.6385 - val_loss: 1.1428 - val_acc: 0.5969\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9970 - acc: 0.6518 - val_loss: 1.0600 - val_acc: 0.6272\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9706 - acc: 0.6609 - val_loss: 1.0443 - val_acc: 0.6314\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9440 - acc: 0.6716 - val_loss: 1.0192 - val_acc: 0.6439\n",
      "\n",
      "model 2/10 - generation 15/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.5128 - acc: 0.4635 - val_loss: 1.3004 - val_acc: 0.5356\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2173 - acc: 0.5738 - val_loss: 1.2125 - val_acc: 0.5855\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0959 - acc: 0.6165 - val_loss: 1.3745 - val_acc: 0.5252\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0177 - acc: 0.6488 - val_loss: 1.1284 - val_acc: 0.6064\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9565 - acc: 0.6691 - val_loss: 1.1965 - val_acc: 0.5912\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9103 - acc: 0.6861 - val_loss: 1.1643 - val_acc: 0.5912\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "model 3/10 - generation 15/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.4563 - acc: 0.4842 - val_loss: 1.2380 - val_acc: 0.5575\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1343 - acc: 0.6042 - val_loss: 1.1392 - val_acc: 0.6047\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0039 - acc: 0.6541 - val_loss: 1.0954 - val_acc: 0.6230\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9228 - acc: 0.6833 - val_loss: 1.1402 - val_acc: 0.6099\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8639 - acc: 0.7053 - val_loss: 1.0543 - val_acc: 0.6379\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8177 - acc: 0.7224 - val_loss: 1.0553 - val_acc: 0.6431\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7716 - acc: 0.7393 - val_loss: 1.0545 - val_acc: 0.6440\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 4/10 - generation 15/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.6207 - acc: 0.4369 - val_loss: 1.3509 - val_acc: 0.5172\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2295 - acc: 0.5685 - val_loss: 1.2286 - val_acc: 0.5679\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0970 - acc: 0.6185 - val_loss: 1.1968 - val_acc: 0.5847\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0199 - acc: 0.6454 - val_loss: 1.1862 - val_acc: 0.5910\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 18s - loss: 0.9719 - acc: 0.6624 - val_loss: 1.1424 - val_acc: 0.6028\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9142 - acc: 0.6833 - val_loss: 1.1521 - val_acc: 0.6084\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8624 - acc: 0.6981 - val_loss: 1.1255 - val_acc: 0.6188\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8148 - acc: 0.7179 - val_loss: 1.1566 - val_acc: 0.6106\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7793 - acc: 0.7278 - val_loss: 1.1537 - val_acc: 0.6147\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 5/10 - generation 15/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 3.9654 - acc: 0.3644 - val_loss: 1.4596 - val_acc: 0.4809\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.3009 - acc: 0.5404 - val_loss: 1.3163 - val_acc: 0.5313\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.1803 - acc: 0.5832 - val_loss: 1.1731 - val_acc: 0.5855\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0975 - acc: 0.6138 - val_loss: 1.1447 - val_acc: 0.5942\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0345 - acc: 0.6361 - val_loss: 1.1207 - val_acc: 0.6040\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9823 - acc: 0.6568 - val_loss: 1.0745 - val_acc: 0.6208\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9369 - acc: 0.6734 - val_loss: 1.0432 - val_acc: 0.6334\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9015 - acc: 0.6860 - val_loss: 1.0800 - val_acc: 0.6228\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8699 - acc: 0.6958 - val_loss: 1.0442 - val_acc: 0.6336\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 6/10 - generation 15/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.5936 - acc: 0.4350 - val_loss: 1.3721 - val_acc: 0.5084\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2121 - acc: 0.5743 - val_loss: 1.2384 - val_acc: 0.5659\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0819 - acc: 0.6229 - val_loss: 1.1887 - val_acc: 0.5824\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9903 - acc: 0.6576 - val_loss: 1.1776 - val_acc: 0.5938\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9168 - acc: 0.6814 - val_loss: 1.1245 - val_acc: 0.6140\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8507 - acc: 0.7042 - val_loss: 1.0952 - val_acc: 0.6218\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8099 - acc: 0.7199 - val_loss: 1.1222 - val_acc: 0.6180\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7700 - acc: 0.7348 - val_loss: 1.1088 - val_acc: 0.6263\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 7/10 - generation 15/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 14.4970 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 00002: early stopping\n",
      "\n",
      "model 8/10 - generation 15/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.6935 - acc: 0.3926 - val_loss: 1.5283 - val_acc: 0.4520\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.3896 - acc: 0.5060 - val_loss: 1.3524 - val_acc: 0.5165\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2811 - acc: 0.5477 - val_loss: 1.2460 - val_acc: 0.5592\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1717 - acc: 0.5891 - val_loss: 1.2044 - val_acc: 0.5790\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0956 - acc: 0.6181 - val_loss: 1.1671 - val_acc: 0.5919\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0360 - acc: 0.6373 - val_loss: 1.1467 - val_acc: 0.5963\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9822 - acc: 0.6581 - val_loss: 1.1084 - val_acc: 0.6140\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9433 - acc: 0.6684 - val_loss: 1.1018 - val_acc: 0.6169\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9137 - acc: 0.6799 - val_loss: 1.0885 - val_acc: 0.6220\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8887 - acc: 0.6893 - val_loss: 1.0823 - val_acc: 0.6212\n",
      "\n",
      "model 9/10 - generation 15/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.6773 - acc: 0.4050 - val_loss: 1.4212 - val_acc: 0.5080\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2908 - acc: 0.5452 - val_loss: 1.3021 - val_acc: 0.5570\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1667 - acc: 0.5933 - val_loss: 1.1720 - val_acc: 0.5947\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0846 - acc: 0.6223 - val_loss: 1.1605 - val_acc: 0.5979\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0375 - acc: 0.6388 - val_loss: 1.0973 - val_acc: 0.6247\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0070 - acc: 0.6502 - val_loss: 1.1027 - val_acc: 0.6212\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9831 - acc: 0.6574 - val_loss: 1.1124 - val_acc: 0.6208\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 10/10 - generation 15/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.5483 - acc: 0.4517 - val_loss: 1.3397 - val_acc: 0.5523\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2028 - acc: 0.5781 - val_loss: 1.2329 - val_acc: 0.5729\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1173 - acc: 0.6090 - val_loss: 1.2097 - val_acc: 0.5928\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0688 - acc: 0.6277 - val_loss: 1.1013 - val_acc: 0.6223\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0229 - acc: 0.6432 - val_loss: 1.0879 - val_acc: 0.6321\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9913 - acc: 0.6527 - val_loss: 1.0715 - val_acc: 0.6322\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9651 - acc: 0.6623 - val_loss: 1.0662 - val_acc: 0.6277\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9466 - acc: 0.6686 - val_loss: 1.0519 - val_acc: 0.6409\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9261 - acc: 0.6759 - val_loss: 1.0254 - val_acc: 0.6472\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9076 - acc: 0.6822 - val_loss: 1.0302 - val_acc: 0.6436\n",
      "Generation 15:\t\tbest accuracy: 0.6440\t\taverage: 0.5739\t\tstd: 0.1587\n",
      "\n",
      "model 1/10 - generation 16/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 2.8649 - acc: 0.3758 - val_loss: 1.4670 - val_acc: 0.4992\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.3262 - acc: 0.5313 - val_loss: 1.2621 - val_acc: 0.5518\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1933 - acc: 0.5803 - val_loss: 1.2052 - val_acc: 0.5763\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0946 - acc: 0.6141 - val_loss: 1.1801 - val_acc: 0.5791\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0275 - acc: 0.6414 - val_loss: 1.0798 - val_acc: 0.6191\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9693 - acc: 0.6611 - val_loss: 1.0881 - val_acc: 0.6139\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9218 - acc: 0.6785 - val_loss: 1.0175 - val_acc: 0.6463\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8853 - acc: 0.6943 - val_loss: 1.0515 - val_acc: 0.6315\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8555 - acc: 0.7028 - val_loss: 1.0000 - val_acc: 0.6488\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8295 - acc: 0.7117 - val_loss: 1.0217 - val_acc: 0.6433\n",
      "\n",
      "model 2/10 - generation 16/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.4642 - acc: 0.4797 - val_loss: 1.3468 - val_acc: 0.5286\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1356 - acc: 0.6012 - val_loss: 1.2729 - val_acc: 0.5509\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9957 - acc: 0.6526 - val_loss: 1.2506 - val_acc: 0.5697\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9108 - acc: 0.6846 - val_loss: 1.0958 - val_acc: 0.6204\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8484 - acc: 0.7084 - val_loss: 1.0555 - val_acc: 0.6331\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7957 - acc: 0.7280 - val_loss: 1.1205 - val_acc: 0.6182\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7524 - acc: 0.7421 - val_loss: 1.1904 - val_acc: 0.5904\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 3/10 - generation 16/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 3.0077 - acc: 0.4043 - val_loss: 1.4501 - val_acc: 0.4981\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2902 - acc: 0.5496 - val_loss: 1.2758 - val_acc: 0.5488\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.1749 - acc: 0.5869 - val_loss: 1.2052 - val_acc: 0.5749\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0976 - acc: 0.6161 - val_loss: 1.1411 - val_acc: 0.5976\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0327 - acc: 0.6391 - val_loss: 1.1238 - val_acc: 0.6034\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9819 - acc: 0.6595 - val_loss: 1.0722 - val_acc: 0.6232\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9388 - acc: 0.6727 - val_loss: 1.0674 - val_acc: 0.6239\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9021 - acc: 0.6870 - val_loss: 1.0800 - val_acc: 0.6253\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8734 - acc: 0.6975 - val_loss: 1.0252 - val_acc: 0.6446\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8483 - acc: 0.7056 - val_loss: 1.0621 - val_acc: 0.6357\n",
      "\n",
      "model 4/10 - generation 16/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.5235 - acc: 0.4611 - val_loss: 1.3743 - val_acc: 0.5182\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1727 - acc: 0.5890 - val_loss: 1.4008 - val_acc: 0.5168\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0422 - acc: 0.6388 - val_loss: 1.1090 - val_acc: 0.6135\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9622 - acc: 0.6705 - val_loss: 1.0886 - val_acc: 0.6251\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9031 - acc: 0.6892 - val_loss: 1.0334 - val_acc: 0.6420\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8627 - acc: 0.7014 - val_loss: 1.1760 - val_acc: 0.6017\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8231 - acc: 0.7169 - val_loss: 1.0614 - val_acc: 0.6401\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 5/10 - generation 16/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.6478 - acc: 0.4082 - val_loss: 1.4783 - val_acc: 0.4835\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2960 - acc: 0.5407 - val_loss: 1.2592 - val_acc: 0.5694\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1826 - acc: 0.5829 - val_loss: 1.2167 - val_acc: 0.5857\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1178 - acc: 0.6079 - val_loss: 1.1585 - val_acc: 0.6059\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0711 - acc: 0.6259 - val_loss: 1.1236 - val_acc: 0.6153\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0409 - acc: 0.6371 - val_loss: 1.2144 - val_acc: 0.5765\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0068 - acc: 0.6480 - val_loss: 1.0762 - val_acc: 0.6304\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9832 - acc: 0.6580 - val_loss: 1.0830 - val_acc: 0.6247\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9623 - acc: 0.6644 - val_loss: 1.0526 - val_acc: 0.6377\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9402 - acc: 0.6716 - val_loss: 1.0409 - val_acc: 0.6439\n",
      "\n",
      "model 6/10 - generation 16/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.6580 - acc: 0.4004 - val_loss: 1.4663 - val_acc: 0.4902\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.3858 - acc: 0.5074 - val_loss: 1.4099 - val_acc: 0.5179\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2727 - acc: 0.5510 - val_loss: 1.3197 - val_acc: 0.5455\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1906 - acc: 0.5800 - val_loss: 1.2956 - val_acc: 0.5477\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1384 - acc: 0.6027 - val_loss: 1.1909 - val_acc: 0.5867\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0914 - acc: 0.6193 - val_loss: 1.1533 - val_acc: 0.6013\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0554 - acc: 0.6309 - val_loss: 1.1154 - val_acc: 0.6151\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0212 - acc: 0.6444 - val_loss: 1.1137 - val_acc: 0.6093\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9968 - acc: 0.6524 - val_loss: 1.0792 - val_acc: 0.6231\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9740 - acc: 0.6598 - val_loss: 1.0465 - val_acc: 0.6378\n",
      "\n",
      "model 7/10 - generation 16/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 29s - loss: 14.4994 - acc: 0.0999 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 26s - loss: 14.3837 - acc: 0.1064 - val_loss: 13.8380 - val_acc: 0.1368\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 26s - loss: 13.7077 - acc: 0.1415 - val_loss: 13.5452 - val_acc: 0.1497\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 26s - loss: 13.4271 - acc: 0.1505 - val_loss: 13.4270 - val_acc: 0.1316\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 26s - loss: 13.2053 - acc: 0.1557 - val_loss: 13.1265 - val_acc: 0.1593\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 26s - loss: 12.9243 - acc: 0.1715 - val_loss: 11.8852 - val_acc: 0.2327\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 26s - loss: 11.7498 - acc: 0.2381 - val_loss: 11.7348 - val_acc: 0.2329\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 26s - loss: 11.5651 - acc: 0.2478 - val_loss: 11.5393 - val_acc: 0.2452\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 26s - loss: 11.2213 - acc: 0.2606 - val_loss: 10.6447 - val_acc: 0.2653\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 26s - loss: 10.3490 - acc: 0.2940 - val_loss: 10.2460 - val_acc: 0.2848\n",
      "\n",
      "model 8/10 - generation 16/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 22s - loss: 1.4880 - acc: 0.4704 - val_loss: 1.2822 - val_acc: 0.5484\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1614 - acc: 0.5934 - val_loss: 1.1934 - val_acc: 0.5847\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0496 - acc: 0.6364 - val_loss: 1.1111 - val_acc: 0.6151\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9729 - acc: 0.6645 - val_loss: 1.0981 - val_acc: 0.6171\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9245 - acc: 0.6816 - val_loss: 1.1731 - val_acc: 0.5931\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8789 - acc: 0.6976 - val_loss: 1.0585 - val_acc: 0.6367\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8417 - acc: 0.7115 - val_loss: 1.0225 - val_acc: 0.6492\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8138 - acc: 0.7209 - val_loss: 1.0777 - val_acc: 0.6314\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7832 - acc: 0.7324 - val_loss: 1.0678 - val_acc: 0.6356\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 9/10 - generation 16/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.5097 - acc: 0.4644 - val_loss: 1.2680 - val_acc: 0.5557\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1788 - acc: 0.5872 - val_loss: 1.2756 - val_acc: 0.5610\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0622 - acc: 0.6322 - val_loss: 1.1213 - val_acc: 0.6109\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9926 - acc: 0.6563 - val_loss: 1.0811 - val_acc: 0.6257\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9436 - acc: 0.6734 - val_loss: 1.0192 - val_acc: 0.6517\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9081 - acc: 0.6859 - val_loss: 1.1277 - val_acc: 0.6065\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8755 - acc: 0.7001 - val_loss: 1.0478 - val_acc: 0.6307\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 10/10 - generation 16/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6204 - acc: 0.4508 - val_loss: 1.2846 - val_acc: 0.5388\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2000 - acc: 0.5774 - val_loss: 1.2410 - val_acc: 0.5627\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0780 - acc: 0.6189 - val_loss: 1.1573 - val_acc: 0.5912\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0035 - acc: 0.6492 - val_loss: 1.0509 - val_acc: 0.6266\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9623 - acc: 0.6627 - val_loss: 1.0446 - val_acc: 0.6333\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9283 - acc: 0.6733 - val_loss: 1.0001 - val_acc: 0.6475\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8998 - acc: 0.6860 - val_loss: 1.0744 - val_acc: 0.6295\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8777 - acc: 0.6953 - val_loss: 0.9497 - val_acc: 0.6668\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8588 - acc: 0.7005 - val_loss: 1.0133 - val_acc: 0.6471\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8432 - acc: 0.7070 - val_loss: 0.9600 - val_acc: 0.6639\n",
      "Epoch 00009: early stopping\n",
      "Generation 16:\t\tbest accuracy: 0.6639\t\taverage: 0.6006\t\tstd: 0.1067\n",
      "\n",
      "model 1/10 - generation 17/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6451 - acc: 0.4082 - val_loss: 1.4955 - val_acc: 0.4660\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3453 - acc: 0.5255 - val_loss: 1.2841 - val_acc: 0.5618\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1897 - acc: 0.5854 - val_loss: 1.1709 - val_acc: 0.6029\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1008 - acc: 0.6175 - val_loss: 1.1745 - val_acc: 0.5911\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0517 - acc: 0.6317 - val_loss: 1.0743 - val_acc: 0.6355\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0127 - acc: 0.6501 - val_loss: 1.0519 - val_acc: 0.6391\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9863 - acc: 0.6583 - val_loss: 1.0525 - val_acc: 0.6356\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9633 - acc: 0.6660 - val_loss: 1.0384 - val_acc: 0.6369\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9417 - acc: 0.6752 - val_loss: 1.0119 - val_acc: 0.6542\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9273 - acc: 0.6780 - val_loss: 0.9979 - val_acc: 0.6607\n",
      "\n",
      "model 2/10 - generation 17/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.5857 - acc: 0.4658 - val_loss: 1.3737 - val_acc: 0.5174\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1907 - acc: 0.5767 - val_loss: 1.1768 - val_acc: 0.5846\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0834 - acc: 0.6172 - val_loss: 1.0715 - val_acc: 0.6253\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0175 - acc: 0.6424 - val_loss: 1.0249 - val_acc: 0.6411\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9694 - acc: 0.6598 - val_loss: 1.0524 - val_acc: 0.6328\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9321 - acc: 0.6742 - val_loss: 1.0102 - val_acc: 0.6491\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9027 - acc: 0.6867 - val_loss: 0.9750 - val_acc: 0.6582\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8800 - acc: 0.6946 - val_loss: 1.0606 - val_acc: 0.6362\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8626 - acc: 0.6994 - val_loss: 0.9531 - val_acc: 0.6662\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8441 - acc: 0.7069 - val_loss: 0.9493 - val_acc: 0.6697\n",
      "\n",
      "model 3/10 - generation 17/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.6360 - acc: 0.4302 - val_loss: 1.3916 - val_acc: 0.5190\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.3073 - acc: 0.5408 - val_loss: 1.2913 - val_acc: 0.5611\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2003 - acc: 0.5810 - val_loss: 1.2204 - val_acc: 0.5841\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1436 - acc: 0.6013 - val_loss: 1.1897 - val_acc: 0.5928\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1091 - acc: 0.6145 - val_loss: 1.1400 - val_acc: 0.6115\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0828 - acc: 0.6255 - val_loss: 1.1566 - val_acc: 0.6030\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0535 - acc: 0.6356 - val_loss: 1.1098 - val_acc: 0.6227\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0259 - acc: 0.6422 - val_loss: 1.0987 - val_acc: 0.6240\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0041 - acc: 0.6504 - val_loss: 1.0759 - val_acc: 0.6384\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9751 - acc: 0.6598 - val_loss: 1.0944 - val_acc: 0.6263\n",
      "\n",
      "model 4/10 - generation 17/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 1.4597 - acc: 0.4839 - val_loss: 1.2631 - val_acc: 0.5521\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1284 - acc: 0.6063 - val_loss: 1.2248 - val_acc: 0.5831\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9959 - acc: 0.6545 - val_loss: 1.0876 - val_acc: 0.6226\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9104 - acc: 0.6854 - val_loss: 1.1212 - val_acc: 0.6080\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8455 - acc: 0.7089 - val_loss: 1.0735 - val_acc: 0.6245\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7936 - acc: 0.7292 - val_loss: 1.1190 - val_acc: 0.6198\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7499 - acc: 0.7444 - val_loss: 1.0512 - val_acc: 0.6362\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7123 - acc: 0.7563 - val_loss: 1.1131 - val_acc: 0.6211\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.6825 - acc: 0.7698 - val_loss: 1.0719 - val_acc: 0.6343\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 5/10 - generation 17/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.8217 - acc: 0.3474 - val_loss: 1.7967 - val_acc: 0.3683\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.4212 - acc: 0.4912 - val_loss: 1.4500 - val_acc: 0.4832\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2616 - acc: 0.5503 - val_loss: 1.2886 - val_acc: 0.5397\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1717 - acc: 0.5865 - val_loss: 1.1876 - val_acc: 0.5781\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0986 - acc: 0.6128 - val_loss: 1.1568 - val_acc: 0.5960\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0358 - acc: 0.6360 - val_loss: 1.1090 - val_acc: 0.6051\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9847 - acc: 0.6547 - val_loss: 1.1147 - val_acc: 0.6107\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9408 - acc: 0.6708 - val_loss: 1.0699 - val_acc: 0.6261\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9058 - acc: 0.6822 - val_loss: 1.0717 - val_acc: 0.6253\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8749 - acc: 0.6953 - val_loss: 1.0866 - val_acc: 0.6262\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "model 6/10 - generation 17/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.5546 - acc: 0.4461 - val_loss: 1.3977 - val_acc: 0.5127\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2469 - acc: 0.5611 - val_loss: 1.2538 - val_acc: 0.5637\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1637 - acc: 0.5892 - val_loss: 1.2202 - val_acc: 0.5751\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0901 - acc: 0.6180 - val_loss: 1.1276 - val_acc: 0.6083\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0332 - acc: 0.6394 - val_loss: 1.0826 - val_acc: 0.6279\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9929 - acc: 0.6542 - val_loss: 1.0730 - val_acc: 0.6280\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9622 - acc: 0.6651 - val_loss: 1.0245 - val_acc: 0.6478\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9418 - acc: 0.6716 - val_loss: 1.0185 - val_acc: 0.6517\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9218 - acc: 0.6807 - val_loss: 1.0084 - val_acc: 0.6549\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9058 - acc: 0.6863 - val_loss: 1.0130 - val_acc: 0.6541\n",
      "\n",
      "model 7/10 - generation 17/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.6173 - acc: 0.4185 - val_loss: 1.4105 - val_acc: 0.5038\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2820 - acc: 0.5490 - val_loss: 1.2830 - val_acc: 0.5713\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1824 - acc: 0.5843 - val_loss: 1.2994 - val_acc: 0.5412\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1213 - acc: 0.6090 - val_loss: 1.1763 - val_acc: 0.5978\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0835 - acc: 0.6203 - val_loss: 1.1421 - val_acc: 0.6116\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0421 - acc: 0.6365 - val_loss: 1.1066 - val_acc: 0.6204\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0190 - acc: 0.6436 - val_loss: 1.1134 - val_acc: 0.6240\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9963 - acc: 0.6545 - val_loss: 1.0744 - val_acc: 0.6332\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9769 - acc: 0.6612 - val_loss: 1.0906 - val_acc: 0.6265\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9587 - acc: 0.6651 - val_loss: 1.0563 - val_acc: 0.6417\n",
      "\n",
      "model 8/10 - generation 17/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.5649 - acc: 0.4426 - val_loss: 1.3212 - val_acc: 0.5449\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2486 - acc: 0.5602 - val_loss: 1.2467 - val_acc: 0.5641\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1404 - acc: 0.6004 - val_loss: 1.2222 - val_acc: 0.5631\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0720 - acc: 0.6277 - val_loss: 1.0693 - val_acc: 0.6342\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0123 - acc: 0.6513 - val_loss: 1.1585 - val_acc: 0.6094\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9749 - acc: 0.6640 - val_loss: 1.0525 - val_acc: 0.6406\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9372 - acc: 0.6760 - val_loss: 1.0779 - val_acc: 0.6308\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9169 - acc: 0.6836 - val_loss: 0.9560 - val_acc: 0.6738\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8889 - acc: 0.6944 - val_loss: 1.1003 - val_acc: 0.6255\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8697 - acc: 0.6981 - val_loss: 1.4076 - val_acc: 0.5138\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "model 9/10 - generation 17/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.7191 - acc: 0.4395 - val_loss: 1.4586 - val_acc: 0.4842\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2613 - acc: 0.5533 - val_loss: 1.2285 - val_acc: 0.5599\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1531 - acc: 0.5931 - val_loss: 1.2075 - val_acc: 0.5750\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0940 - acc: 0.6144 - val_loss: 1.1018 - val_acc: 0.6079\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0508 - acc: 0.6313 - val_loss: 1.1482 - val_acc: 0.5907\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0216 - acc: 0.6421 - val_loss: 1.0791 - val_acc: 0.6172\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0001 - acc: 0.6484 - val_loss: 1.0900 - val_acc: 0.6129\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9783 - acc: 0.6546 - val_loss: 1.0521 - val_acc: 0.6273\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9640 - acc: 0.6611 - val_loss: 1.0575 - val_acc: 0.6277\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9418 - acc: 0.6723 - val_loss: 1.0708 - val_acc: 0.6249\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "model 10/10 - generation 17/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 2.7278 - acc: 0.4024 - val_loss: 1.4573 - val_acc: 0.4808\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.3096 - acc: 0.5425 - val_loss: 1.2324 - val_acc: 0.5653\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 19s - loss: 1.1793 - acc: 0.5857 - val_loss: 1.1853 - val_acc: 0.5816\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0962 - acc: 0.6157 - val_loss: 1.1501 - val_acc: 0.5946\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0393 - acc: 0.6363 - val_loss: 1.1256 - val_acc: 0.6038\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9918 - acc: 0.6528 - val_loss: 1.0932 - val_acc: 0.6129\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9562 - acc: 0.6658 - val_loss: 1.0944 - val_acc: 0.6181\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9256 - acc: 0.6779 - val_loss: 1.1477 - val_acc: 0.5947\n",
      "Epoch 00007: early stopping\n",
      "Generation 17:\t\tbest accuracy: 0.6697\t\taverage: 0.6246\t\tstd: 0.0422\n",
      "\n",
      "model 1/10 - generation 18/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.5049 - acc: 0.4652 - val_loss: 1.3323 - val_acc: 0.5434\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2172 - acc: 0.5708 - val_loss: 1.2257 - val_acc: 0.5779\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1151 - acc: 0.6080 - val_loss: 1.1412 - val_acc: 0.6028\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0566 - acc: 0.6297 - val_loss: 1.0998 - val_acc: 0.6189\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0116 - acc: 0.6467 - val_loss: 1.0675 - val_acc: 0.6330\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9770 - acc: 0.6595 - val_loss: 1.0755 - val_acc: 0.6327\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9483 - acc: 0.6686 - val_loss: 1.0227 - val_acc: 0.6440\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9249 - acc: 0.6774 - val_loss: 1.0057 - val_acc: 0.6502\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9073 - acc: 0.6861 - val_loss: 1.0026 - val_acc: 0.6551\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8886 - acc: 0.6921 - val_loss: 0.9835 - val_acc: 0.6616\n",
      "\n",
      "model 2/10 - generation 18/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.7451 - acc: 0.4193 - val_loss: 1.4008 - val_acc: 0.4994\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.3121 - acc: 0.5340 - val_loss: 1.2318 - val_acc: 0.5584\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2254 - acc: 0.5657 - val_loss: 1.1952 - val_acc: 0.5706\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1680 - acc: 0.5879 - val_loss: 1.1601 - val_acc: 0.5850\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1281 - acc: 0.6015 - val_loss: 1.1527 - val_acc: 0.5933\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.1016 - acc: 0.6121 - val_loss: 1.2122 - val_acc: 0.5695\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0758 - acc: 0.6201 - val_loss: 1.0979 - val_acc: 0.6092\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0541 - acc: 0.6289 - val_loss: 1.1068 - val_acc: 0.6047\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0325 - acc: 0.6354 - val_loss: 1.0920 - val_acc: 0.6101\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0266 - acc: 0.6373 - val_loss: 1.0697 - val_acc: 0.6208\n",
      "\n",
      "model 3/10 - generation 18/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.7732 - acc: 0.3505 - val_loss: 1.6858 - val_acc: 0.3619\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.4642 - acc: 0.4716 - val_loss: 1.4563 - val_acc: 0.4822\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3572 - acc: 0.5177 - val_loss: 1.3860 - val_acc: 0.5182\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2860 - acc: 0.5451 - val_loss: 1.3102 - val_acc: 0.5533\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2234 - acc: 0.5707 - val_loss: 1.2601 - val_acc: 0.5641\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1703 - acc: 0.5887 - val_loss: 1.2187 - val_acc: 0.5725\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1274 - acc: 0.6036 - val_loss: 1.2310 - val_acc: 0.5693\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0908 - acc: 0.6165 - val_loss: 1.1516 - val_acc: 0.5936\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0573 - acc: 0.6321 - val_loss: 1.1223 - val_acc: 0.6161\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0314 - acc: 0.6381 - val_loss: 1.1071 - val_acc: 0.6155\n",
      "\n",
      "model 4/10 - generation 18/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 3.5675 - acc: 0.3567 - val_loss: 1.3971 - val_acc: 0.5039\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.3140 - acc: 0.5365 - val_loss: 1.4162 - val_acc: 0.5025\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.1911 - acc: 0.5814 - val_loss: 1.2175 - val_acc: 0.5733\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.1117 - acc: 0.6111 - val_loss: 1.1665 - val_acc: 0.5826\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0471 - acc: 0.6334 - val_loss: 1.1411 - val_acc: 0.5948\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9959 - acc: 0.6525 - val_loss: 1.1438 - val_acc: 0.6013\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9509 - acc: 0.6691 - val_loss: 1.0863 - val_acc: 0.6226\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9104 - acc: 0.6829 - val_loss: 1.0863 - val_acc: 0.6178\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8802 - acc: 0.6941 - val_loss: 1.0769 - val_acc: 0.6230\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8542 - acc: 0.7037 - val_loss: 1.0418 - val_acc: 0.6351\n",
      "\n",
      "model 5/10 - generation 18/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 1.6322 - acc: 0.4117 - val_loss: 1.3547 - val_acc: 0.5174\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2539 - acc: 0.5561 - val_loss: 1.2041 - val_acc: 0.5704\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1286 - acc: 0.6045 - val_loss: 1.1459 - val_acc: 0.5917\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0499 - acc: 0.6303 - val_loss: 1.1535 - val_acc: 0.5932\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9948 - acc: 0.6535 - val_loss: 1.0918 - val_acc: 0.6155\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9556 - acc: 0.6672 - val_loss: 1.0751 - val_acc: 0.6271\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9116 - acc: 0.6825 - val_loss: 1.0590 - val_acc: 0.6282\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8786 - acc: 0.6924 - val_loss: 1.0959 - val_acc: 0.6228\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8449 - acc: 0.7033 - val_loss: 1.0590 - val_acc: 0.6313\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 6/10 - generation 18/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.5583 - acc: 0.4451 - val_loss: 1.4059 - val_acc: 0.4958\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2387 - acc: 0.5666 - val_loss: 1.2262 - val_acc: 0.5785\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1345 - acc: 0.6032 - val_loss: 1.1516 - val_acc: 0.6006\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0788 - acc: 0.6239 - val_loss: 1.1278 - val_acc: 0.6045\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0307 - acc: 0.6421 - val_loss: 1.1462 - val_acc: 0.5969\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9921 - acc: 0.6546 - val_loss: 1.0701 - val_acc: 0.6306\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9608 - acc: 0.6652 - val_loss: 1.0493 - val_acc: 0.6345\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9338 - acc: 0.6764 - val_loss: 1.0476 - val_acc: 0.6366\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9134 - acc: 0.6819 - val_loss: 1.0264 - val_acc: 0.6481\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9004 - acc: 0.6854 - val_loss: 1.0289 - val_acc: 0.6389\n",
      "\n",
      "model 7/10 - generation 18/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 1.6117 - acc: 0.4303 - val_loss: 1.2794 - val_acc: 0.5342\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.1950 - acc: 0.5770 - val_loss: 1.1542 - val_acc: 0.5829\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0488 - acc: 0.6322 - val_loss: 1.0412 - val_acc: 0.6333\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9808 - acc: 0.6548 - val_loss: 1.0080 - val_acc: 0.6496\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9244 - acc: 0.6783 - val_loss: 0.9837 - val_acc: 0.6563\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8918 - acc: 0.6866 - val_loss: 1.0367 - val_acc: 0.6432\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8677 - acc: 0.6964 - val_loss: 0.9260 - val_acc: 0.6749\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8390 - acc: 0.7086 - val_loss: 0.8977 - val_acc: 0.6856\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8182 - acc: 0.7151 - val_loss: 1.0246 - val_acc: 0.6532\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.7999 - acc: 0.7226 - val_loss: 0.8153 - val_acc: 0.7174\n",
      "\n",
      "model 8/10 - generation 18/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.5315 - acc: 0.4588 - val_loss: 1.3478 - val_acc: 0.5338\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2084 - acc: 0.5743 - val_loss: 1.1910 - val_acc: 0.5911\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1125 - acc: 0.6112 - val_loss: 1.1386 - val_acc: 0.6071\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0522 - acc: 0.6317 - val_loss: 1.0801 - val_acc: 0.6249\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0116 - acc: 0.6457 - val_loss: 1.0617 - val_acc: 0.6335\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9734 - acc: 0.6614 - val_loss: 1.0292 - val_acc: 0.6500\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9468 - acc: 0.6690 - val_loss: 1.0046 - val_acc: 0.6548\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9249 - acc: 0.6790 - val_loss: 0.9982 - val_acc: 0.6568\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9037 - acc: 0.6865 - val_loss: 0.9870 - val_acc: 0.6619\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8825 - acc: 0.6916 - val_loss: 0.9649 - val_acc: 0.6663\n",
      "\n",
      "model 9/10 - generation 18/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.4728 - acc: 0.4771 - val_loss: 1.3032 - val_acc: 0.5451\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1298 - acc: 0.6062 - val_loss: 1.2271 - val_acc: 0.5751\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0038 - acc: 0.6530 - val_loss: 1.1364 - val_acc: 0.6031\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9375 - acc: 0.6756 - val_loss: 1.0526 - val_acc: 0.6425\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8890 - acc: 0.6933 - val_loss: 1.1921 - val_acc: 0.5949\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8508 - acc: 0.7087 - val_loss: 1.2022 - val_acc: 0.5849\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "model 10/10 - generation 18/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.5470 - acc: 0.4484 - val_loss: 1.3463 - val_acc: 0.5391\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2268 - acc: 0.5702 - val_loss: 1.2007 - val_acc: 0.5894\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1196 - acc: 0.6081 - val_loss: 1.1576 - val_acc: 0.6081\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0566 - acc: 0.6346 - val_loss: 1.0721 - val_acc: 0.6353\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0111 - acc: 0.6491 - val_loss: 1.0552 - val_acc: 0.6403\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9752 - acc: 0.6604 - val_loss: 1.0463 - val_acc: 0.6376\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9485 - acc: 0.6724 - val_loss: 1.0291 - val_acc: 0.6463\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9277 - acc: 0.6781 - val_loss: 0.9983 - val_acc: 0.6586\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9104 - acc: 0.6832 - val_loss: 0.9833 - val_acc: 0.6627\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8916 - acc: 0.6917 - val_loss: 0.9901 - val_acc: 0.6617\n",
      "Generation 18:\t\tbest accuracy: 0.7174\t\taverage: 0.6433\t\tstd: 0.0341\n",
      "\n",
      "model 1/10 - generation 19/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6214 - acc: 0.4534 - val_loss: 1.4183 - val_acc: 0.5040\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2286 - acc: 0.5649 - val_loss: 1.2453 - val_acc: 0.5568\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1142 - acc: 0.6051 - val_loss: 1.1422 - val_acc: 0.5981\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0352 - acc: 0.6351 - val_loss: 1.1445 - val_acc: 0.5984\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9832 - acc: 0.6539 - val_loss: 1.0415 - val_acc: 0.6310\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9469 - acc: 0.6688 - val_loss: 1.0772 - val_acc: 0.6246\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9178 - acc: 0.6800 - val_loss: 1.0215 - val_acc: 0.6429\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8936 - acc: 0.6882 - val_loss: 1.0252 - val_acc: 0.6386\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8717 - acc: 0.6965 - val_loss: 0.9617 - val_acc: 0.6662\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8572 - acc: 0.6992 - val_loss: 1.0048 - val_acc: 0.6455\n",
      "\n",
      "model 2/10 - generation 19/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.5321 - acc: 0.4554 - val_loss: 1.3045 - val_acc: 0.5298\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2103 - acc: 0.5707 - val_loss: 1.2511 - val_acc: 0.5561\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.0972 - acc: 0.6122 - val_loss: 1.2734 - val_acc: 0.5590\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0297 - acc: 0.6367 - val_loss: 1.1715 - val_acc: 0.5956\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9864 - acc: 0.6529 - val_loss: 1.1097 - val_acc: 0.6079\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9510 - acc: 0.6646 - val_loss: 1.4152 - val_acc: 0.5336\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 14s - loss: 0.9206 - acc: 0.6778 - val_loss: 1.1190 - val_acc: 0.6128\n",
      "Epoch 00006: early stopping\n",
      "\n",
      "model 3/10 - generation 19/20:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.5832 - acc: 0.4352 - val_loss: 1.3754 - val_acc: 0.4969\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2297 - acc: 0.5667 - val_loss: 1.2195 - val_acc: 0.5698\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1101 - acc: 0.6121 - val_loss: 1.6606 - val_acc: 0.4733\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0410 - acc: 0.6372 - val_loss: 1.1748 - val_acc: 0.5996\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9897 - acc: 0.6539 - val_loss: 1.0499 - val_acc: 0.6324\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9586 - acc: 0.6706 - val_loss: 1.1649 - val_acc: 0.5968\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9271 - acc: 0.6785 - val_loss: 0.9808 - val_acc: 0.6681\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9011 - acc: 0.6899 - val_loss: 1.0333 - val_acc: 0.6516\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.8856 - acc: 0.6964 - val_loss: 0.9957 - val_acc: 0.6537\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 4/10 - generation 19/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 1.6774 - acc: 0.3895 - val_loss: 1.6540 - val_acc: 0.3893\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.3054 - acc: 0.5291 - val_loss: 1.3064 - val_acc: 0.5282\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.1812 - acc: 0.5799 - val_loss: 1.2266 - val_acc: 0.5746\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1062 - acc: 0.6080 - val_loss: 1.1361 - val_acc: 0.6077\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0493 - acc: 0.6290 - val_loss: 1.0861 - val_acc: 0.6233\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0048 - acc: 0.6460 - val_loss: 1.0858 - val_acc: 0.6284\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9711 - acc: 0.6579 - val_loss: 1.0583 - val_acc: 0.6304\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9445 - acc: 0.6702 - val_loss: 1.0199 - val_acc: 0.6506\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9195 - acc: 0.6796 - val_loss: 1.0224 - val_acc: 0.6385\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9021 - acc: 0.6841 - val_loss: 0.9889 - val_acc: 0.6603\n",
      "\n",
      "model 5/10 - generation 19/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.6449 - acc: 0.4138 - val_loss: 1.4781 - val_acc: 0.4948\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.3314 - acc: 0.5276 - val_loss: 1.3092 - val_acc: 0.5480\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.2372 - acc: 0.5652 - val_loss: 1.2872 - val_acc: 0.5545\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1695 - acc: 0.5867 - val_loss: 1.1858 - val_acc: 0.5983\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.1092 - acc: 0.6105 - val_loss: 1.1349 - val_acc: 0.6089\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0578 - acc: 0.6296 - val_loss: 1.0834 - val_acc: 0.6284\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0125 - acc: 0.6473 - val_loss: 1.2042 - val_acc: 0.5843\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9771 - acc: 0.6599 - val_loss: 1.0286 - val_acc: 0.6493\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9481 - acc: 0.6706 - val_loss: 1.0169 - val_acc: 0.6508\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9237 - acc: 0.6781 - val_loss: 1.0267 - val_acc: 0.6468\n",
      "\n",
      "model 6/10 - generation 19/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.5882 - acc: 0.4347 - val_loss: 1.4442 - val_acc: 0.4920\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.3052 - acc: 0.5344 - val_loss: 1.4513 - val_acc: 0.4893\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.2272 - acc: 0.5638 - val_loss: 1.2365 - val_acc: 0.5694\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.1765 - acc: 0.5831 - val_loss: 1.2032 - val_acc: 0.5781\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.1422 - acc: 0.5963 - val_loss: 1.2043 - val_acc: 0.5788\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 12s - loss: 1.1144 - acc: 0.6053 - val_loss: 1.2043 - val_acc: 0.5833\n",
      "Epoch 00005: early stopping\n",
      "\n",
      "model 7/10 - generation 19/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.7225 - acc: 0.3883 - val_loss: 1.5870 - val_acc: 0.4416\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.4067 - acc: 0.4998 - val_loss: 1.3996 - val_acc: 0.5097\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2926 - acc: 0.5442 - val_loss: 1.3673 - val_acc: 0.5191\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1960 - acc: 0.5819 - val_loss: 1.2273 - val_acc: 0.5797\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1255 - acc: 0.6086 - val_loss: 1.1807 - val_acc: 0.5923\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0750 - acc: 0.6264 - val_loss: 1.1503 - val_acc: 0.6063\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0363 - acc: 0.6403 - val_loss: 1.1411 - val_acc: 0.6131\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0068 - acc: 0.6493 - val_loss: 1.0614 - val_acc: 0.6320\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9847 - acc: 0.6577 - val_loss: 1.0703 - val_acc: 0.6307\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9625 - acc: 0.6659 - val_loss: 1.0700 - val_acc: 0.6341\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "model 8/10 - generation 19/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.7150 - acc: 0.4150 - val_loss: 1.4505 - val_acc: 0.4936\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3520 - acc: 0.5145 - val_loss: 1.4476 - val_acc: 0.4991\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2379 - acc: 0.5608 - val_loss: 1.1710 - val_acc: 0.5866\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1568 - acc: 0.5896 - val_loss: 1.1157 - val_acc: 0.6065\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1071 - acc: 0.6091 - val_loss: 1.1664 - val_acc: 0.5900\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0680 - acc: 0.6262 - val_loss: 1.0446 - val_acc: 0.6379\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0413 - acc: 0.6331 - val_loss: 1.0743 - val_acc: 0.6205\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0205 - acc: 0.6442 - val_loss: 1.0196 - val_acc: 0.6409\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0016 - acc: 0.6476 - val_loss: 1.0336 - val_acc: 0.6382\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9899 - acc: 0.6559 - val_loss: 0.9961 - val_acc: 0.6500\n",
      "\n",
      "model 9/10 - generation 19/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 38s - loss: 13.3520 - acc: 0.1690 - val_loss: 13.2575 - val_acc: 0.1760\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 34s - loss: 13.2677 - acc: 0.1754 - val_loss: 13.2055 - val_acc: 0.1795\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 34s - loss: 13.2197 - acc: 0.1780 - val_loss: 13.1739 - val_acc: 0.1815\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 34s - loss: 13.1890 - acc: 0.1798 - val_loss: 13.1677 - val_acc: 0.1816\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 34s - loss: 13.1491 - acc: 0.1825 - val_loss: 13.2151 - val_acc: 0.1779\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 34s - loss: 13.1076 - acc: 0.1846 - val_loss: 13.0659 - val_acc: 0.1865\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 34s - loss: 13.0963 - acc: 0.1855 - val_loss: 13.1273 - val_acc: 0.1838\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 34s - loss: 13.0708 - acc: 0.1870 - val_loss: 13.1179 - val_acc: 0.1836\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 10/10 - generation 19/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.5904 - acc: 0.4313 - val_loss: 1.3688 - val_acc: 0.5240\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2496 - acc: 0.5596 - val_loss: 1.2136 - val_acc: 0.5842\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1289 - acc: 0.6029 - val_loss: 1.1495 - val_acc: 0.6043\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0571 - acc: 0.6314 - val_loss: 1.1271 - val_acc: 0.6021\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0071 - acc: 0.6491 - val_loss: 1.1047 - val_acc: 0.6111\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9654 - acc: 0.6629 - val_loss: 1.0610 - val_acc: 0.6266\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9342 - acc: 0.6756 - val_loss: 1.0169 - val_acc: 0.6508\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9070 - acc: 0.6855 - val_loss: 1.0006 - val_acc: 0.6568\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8894 - acc: 0.6893 - val_loss: 1.0097 - val_acc: 0.6502\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8741 - acc: 0.6968 - val_loss: 0.9788 - val_acc: 0.6614\n",
      "Generation 19:\t\tbest accuracy: 0.6614\t\taverage: 0.5932\t\tstd: 0.1384\n",
      "\n",
      "model 1/10 - generation 20/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 1.5322 - acc: 0.4573 - val_loss: 1.3978 - val_acc: 0.5070\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2510 - acc: 0.5553 - val_loss: 1.3257 - val_acc: 0.5407\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1368 - acc: 0.5997 - val_loss: 1.3457 - val_acc: 0.5401\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0531 - acc: 0.6310 - val_loss: 1.2779 - val_acc: 0.5538\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9978 - acc: 0.6504 - val_loss: 1.3277 - val_acc: 0.5450\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9569 - acc: 0.6667 - val_loss: 1.1065 - val_acc: 0.6164\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9172 - acc: 0.6803 - val_loss: 1.1850 - val_acc: 0.5908\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.8884 - acc: 0.6907 - val_loss: 1.1409 - val_acc: 0.6112\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 2/10 - generation 20/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6579 - acc: 0.4040 - val_loss: 1.5133 - val_acc: 0.4563\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.3211 - acc: 0.5327 - val_loss: 1.2806 - val_acc: 0.5455\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2137 - acc: 0.5702 - val_loss: 1.2129 - val_acc: 0.5773\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1585 - acc: 0.5932 - val_loss: 1.2016 - val_acc: 0.5826\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1216 - acc: 0.6066 - val_loss: 1.1896 - val_acc: 0.5852\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0881 - acc: 0.6166 - val_loss: 1.2336 - val_acc: 0.5657\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0674 - acc: 0.6242 - val_loss: 1.1382 - val_acc: 0.6027\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0388 - acc: 0.6355 - val_loss: 1.1480 - val_acc: 0.6020\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0224 - acc: 0.6409 - val_loss: 1.1460 - val_acc: 0.6001\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 3/10 - generation 20/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.7616 - acc: 0.3626 - val_loss: 1.4893 - val_acc: 0.4847\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.3734 - acc: 0.5100 - val_loss: 1.3453 - val_acc: 0.5358\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2485 - acc: 0.5576 - val_loss: 1.2501 - val_acc: 0.5701\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1831 - acc: 0.5830 - val_loss: 1.2121 - val_acc: 0.5868\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1368 - acc: 0.6014 - val_loss: 1.1692 - val_acc: 0.6021\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0908 - acc: 0.6180 - val_loss: 1.1303 - val_acc: 0.6112\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0512 - acc: 0.6316 - val_loss: 1.0874 - val_acc: 0.6303\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0250 - acc: 0.6436 - val_loss: 1.0667 - val_acc: 0.6316\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9985 - acc: 0.6521 - val_loss: 1.0941 - val_acc: 0.6247\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9818 - acc: 0.6615 - val_loss: 1.0575 - val_acc: 0.6393\n",
      "\n",
      "model 4/10 - generation 20/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.5306 - acc: 0.4632 - val_loss: 1.7127 - val_acc: 0.4388\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1817 - acc: 0.5815 - val_loss: 1.2802 - val_acc: 0.5612\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 15s - loss: 1.0416 - acc: 0.6329 - val_loss: 1.1768 - val_acc: 0.6064\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9518 - acc: 0.6665 - val_loss: 1.0851 - val_acc: 0.6333\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8885 - acc: 0.6898 - val_loss: 1.1506 - val_acc: 0.6197\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8402 - acc: 0.7075 - val_loss: 0.9745 - val_acc: 0.6700\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.8051 - acc: 0.7193 - val_loss: 1.0220 - val_acc: 0.6564\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.7735 - acc: 0.7297 - val_loss: 1.0622 - val_acc: 0.6530\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "model 5/10 - generation 20/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 1.5736 - acc: 0.4403 - val_loss: 1.3695 - val_acc: 0.5118\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.2379 - acc: 0.5618 - val_loss: 1.2695 - val_acc: 0.5611\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1014 - acc: 0.6121 - val_loss: 1.1258 - val_acc: 0.6028\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0289 - acc: 0.6401 - val_loss: 1.0706 - val_acc: 0.6225\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9685 - acc: 0.6624 - val_loss: 1.0605 - val_acc: 0.6289\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9151 - acc: 0.6826 - val_loss: 1.0344 - val_acc: 0.6430\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8655 - acc: 0.7016 - val_loss: 0.9631 - val_acc: 0.6704\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.8251 - acc: 0.7143 - val_loss: 0.9786 - val_acc: 0.6634\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 18s - loss: 0.7914 - acc: 0.7258 - val_loss: 0.9625 - val_acc: 0.6708\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.7627 - acc: 0.7365 - val_loss: 0.9564 - val_acc: 0.6693\n",
      "\n",
      "model 6/10 - generation 20/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 22s - loss: 1.6735 - acc: 0.4091 - val_loss: 1.5372 - val_acc: 0.4372\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.3058 - acc: 0.5368 - val_loss: 1.3021 - val_acc: 0.5341\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.1770 - acc: 0.5837 - val_loss: 2.2405 - val_acc: 0.3538\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0990 - acc: 0.6137 - val_loss: 1.0626 - val_acc: 0.6232\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0508 - acc: 0.6333 - val_loss: 1.0990 - val_acc: 0.6168\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.0165 - acc: 0.6441 - val_loss: 1.0473 - val_acc: 0.6274\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9865 - acc: 0.6599 - val_loss: 0.9951 - val_acc: 0.6468\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9713 - acc: 0.6618 - val_loss: 1.0199 - val_acc: 0.6420\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 18s - loss: 0.9518 - acc: 0.6697 - val_loss: 1.0948 - val_acc: 0.6254\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "model 7/10 - generation 20/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 20s - loss: 1.6410 - acc: 0.4143 - val_loss: 1.4614 - val_acc: 0.4942\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.3305 - acc: 0.5281 - val_loss: 1.2782 - val_acc: 0.5547\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.2134 - acc: 0.5700 - val_loss: 1.2534 - val_acc: 0.5698\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.1416 - acc: 0.5991 - val_loss: 1.1953 - val_acc: 0.5879\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0833 - acc: 0.6201 - val_loss: 1.1370 - val_acc: 0.5998\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0374 - acc: 0.6379 - val_loss: 1.0771 - val_acc: 0.6261\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s - loss: 1.0002 - acc: 0.6499 - val_loss: 1.1304 - val_acc: 0.5971\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9660 - acc: 0.6640 - val_loss: 1.0384 - val_acc: 0.6402\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s - loss: 0.9395 - acc: 0.6736 - val_loss: 1.0178 - val_acc: 0.6486\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 15s - loss: 0.9136 - acc: 0.6811 - val_loss: 1.0129 - val_acc: 0.6481\n",
      "\n",
      "model 8/10 - generation 20/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 23s - loss: 1.6386 - acc: 0.4159 - val_loss: 1.4078 - val_acc: 0.5018\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.3171 - acc: 0.5293 - val_loss: 1.2938 - val_acc: 0.5306\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.1992 - acc: 0.5721 - val_loss: 1.1963 - val_acc: 0.5905\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.1189 - acc: 0.6024 - val_loss: 1.1587 - val_acc: 0.6036\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 19s - loss: 1.0474 - acc: 0.6316 - val_loss: 1.0885 - val_acc: 0.6210\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9943 - acc: 0.6494 - val_loss: 1.0351 - val_acc: 0.6429\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9514 - acc: 0.6669 - val_loss: 1.0183 - val_acc: 0.6482\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.9209 - acc: 0.6771 - val_loss: 1.0071 - val_acc: 0.6514\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8983 - acc: 0.6881 - val_loss: 0.9752 - val_acc: 0.6646\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 19s - loss: 0.8741 - acc: 0.6930 - val_loss: 0.9523 - val_acc: 0.6774\n",
      "\n",
      "model 9/10 - generation 20/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 18s - loss: 1.7778 - acc: 0.3567 - val_loss: 1.5348 - val_acc: 0.4791\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.4210 - acc: 0.4974 - val_loss: 1.4411 - val_acc: 0.5039\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.3364 - acc: 0.5299 - val_loss: 1.3499 - val_acc: 0.5361\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 14s - loss: 1.2846 - acc: 0.5488 - val_loss: 1.3126 - val_acc: 0.5496\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.2449 - acc: 0.5654 - val_loss: 1.2988 - val_acc: 0.5522\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.2175 - acc: 0.5767 - val_loss: 1.2685 - val_acc: 0.5650\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.1967 - acc: 0.5829 - val_loss: 1.2567 - val_acc: 0.5724\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.1806 - acc: 0.5868 - val_loss: 1.2360 - val_acc: 0.5749\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.1664 - acc: 0.5935 - val_loss: 1.2234 - val_acc: 0.5815\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 13s - loss: 1.1530 - acc: 0.5988 - val_loss: 1.2052 - val_acc: 0.5868\n",
      "\n",
      "model 10/10 - generation 20/20:\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s - loss: 1.6000 - acc: 0.4460 - val_loss: 1.4195 - val_acc: 0.4985\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.2466 - acc: 0.5569 - val_loss: 1.2463 - val_acc: 0.5648\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.1427 - acc: 0.5936 - val_loss: 1.2681 - val_acc: 0.5513\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0793 - acc: 0.6193 - val_loss: 1.1357 - val_acc: 0.6024\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 17s - loss: 1.0266 - acc: 0.6385 - val_loss: 1.0589 - val_acc: 0.6384\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9866 - acc: 0.6548 - val_loss: 1.0526 - val_acc: 0.6358\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9612 - acc: 0.6627 - val_loss: 1.0570 - val_acc: 0.6345\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9371 - acc: 0.6728 - val_loss: 0.9841 - val_acc: 0.6607\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9210 - acc: 0.6783 - val_loss: 1.0861 - val_acc: 0.6314\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 17s - loss: 0.9045 - acc: 0.6848 - val_loss: 1.0739 - val_acc: 0.6251\n",
      "Epoch 00009: early stopping\n",
      "Generation 20:\t\tbest accuracy: 0.6774\t\taverage: 0.6336\t\tstd: 0.0279\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_480 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_296 (Bat (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_513 (Activation)  (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_513 (Dropout)        (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_481 (Conv2D)          (None, 32, 32, 8)         4616      \n",
      "_________________________________________________________________\n",
      "activation_514 (Activation)  (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_514 (Dropout)        (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_482 (Conv2D)          (None, 32, 32, 64)        4672      \n",
      "_________________________________________________________________\n",
      "batch_normalization_297 (Bat (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_515 (Activation)  (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_515 (Dropout)        (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_483 (Conv2D)          (None, 32, 32, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_298 (Bat (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_516 (Activation)  (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_516 (Dropout)        (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_104 (MaxPoolin (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_201 (Flatten)        (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "activation_517 (Activation)  (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_517 (Dropout)        (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 4,226,466\n",
      "Trainable params: 4,226,178\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_generations = 20\n",
    "population_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "devol = DEvol(genome_handler)\n",
    "model = devol.run(dataset, num_generations, population_size, num_epochs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of evolutional CNN on MNIST(batchnorm=False, dropout=False)\n",
    "max_conv_layers = 3\n",
    "\n",
    "max_dense_layers = 2 # including final softmax layer\n",
    "\n",
    "max_conv_kernels = 64\n",
    "\n",
    "max_dense_nodes = 1024\n",
    "\n",
    "num_generations = 10\n",
    "\n",
    "population_size = 10\n",
    "\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View experiment result based on index\n",
    "experiment = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch=true, dropout=true, activ=[relu, sigmoid]\n",
    "if experiment == 1:\n",
    "    datafile = \"Sun Oct 29 15:41:54 2017.csv\"\n",
    "    genome_handler = GenomeHandler(max_conv_layers, max_dense_layers, max_conv_kernels, \\\n",
    "                    max_dense_nodes, input_shape, num_classes, \\\n",
    "                    batch_normalization=True, dropout=True, max_pooling=True, \\\n",
    "                optimizers=None, activations=None)\n",
    "    \n",
    "#batch=false, dropout=false, activ=[relu,sigmoid]\n",
    "elif experiment == 2:\n",
    "    datafile = \"Sat Oct 28 20:48:00 2017.csv\"\n",
    "    genome_handler = GenomeHandler(max_conv_layers, max_dense_layers, max_conv_kernels, \\\n",
    "                    max_dense_nodes, input_shape, num_classes, \\\n",
    "                    batch_normalization=False, dropout=False, max_pooling=True, \\\n",
    "                optimizers=None, activations=None)\n",
    "    \n",
    "#batch=false, dropout=false, activ=[sigmoid]\n",
    "elif experiment == 3:\n",
    "    datafile = \"Sun Oct 29 18:06:26 2017.csv\" \n",
    "    genome_handler = GenomeHandler(max_conv_layers, max_dense_layers, max_conv_kernels, \\\n",
    "                    max_dense_nodes, input_shape, num_classes, \\\n",
    "                    batch_normalization=False, dropout=False, max_pooling=True, \\\n",
    "                optimizers=None, activations=[\"sigmoid\"])\n",
    "\n",
    "#batch=false, dropout=false, activ=[relu]    \n",
    "elif experiment == 4:\n",
    "    datafile = \"Sun Oct 29 20:00:59 2017.csv\"\n",
    "    genome_handler = GenomeHandler(max_conv_layers, max_dense_layers, max_conv_kernels, \\\n",
    "                    max_dense_nodes, input_shape, num_classes, \\\n",
    "                    batch_normalization=False, dropout=False, max_pooling=True, \\\n",
    "                optimizers=None, activations=[\"relu\"])\n",
    "\n",
    "elif experiment == 5:\n",
    "    datafile = \"Thu Nov  9 23:50:33 2017.csv\"\n",
    "    genome_handler = GenomeHandler(max_conv_layers, max_dense_layers, max_conv_kernels, \\\n",
    "                    max_dense_nodes, input_shape, num_classes, \\\n",
    "                    batch_normalization=True, dropout=True, max_pooling=True, \\\n",
    "                optimizers=None, activations=activ)\n",
    "\n",
    "# Using current setting    \n",
    "else:\n",
    "    datafile = devol.datafile\n",
    "\n",
    "data = np.genfromtxt(datafile, delimiter=\",\")\n",
    "num_generations = 10   # Default\n",
    "population_size = 10   # Default\n",
    "data = data[1:]\n",
    "#print(data.shape)\n",
    "accuracy = []\n",
    "for row in data:\n",
    "    accuracy.append(row[-1])\n",
    "running_max = scipy.maximum.accumulate(accuracy)\n",
    "accuracy = np.array(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 8)         4616      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        4672      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 16)        9232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 4,226,466\n",
      "Trainable params: 4,226,178\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n",
      "accuracy: 72.81%\n"
     ]
    }
   ],
   "source": [
    "best_model = genome_handler.decode_best(datafile)\n",
    "best_model.summary()\n",
    "print(\"accuracy: {}%\".format(max(accuracy)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running max of accuracy across generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABFUAAALkCAYAAADOJQohAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzMzsxY+BLHdk3gx4JC4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f14c7419588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(range(len(running_max)), running_max)\n",
    "plt.title('Running Max Accuracy vs. Species', fontsize=24)\n",
    "plt.xlabel('Species across generations',fontsize=20)\n",
    "plt.ylabel('Test Accuracy',fontsize=20)\n",
    "plt.tick_params(labelsize=20)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18, 12)\n",
    "plt.savefig('plot/runningmax_'+ str(experiment) +'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy scattered across generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDwAAALkCAYAAADj1yWbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVLtGHhIkiRJkqTaMfCQJEmSJEm18/8BRPG1jG3vxekAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f14c73b59e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2)\n",
    "plt.scatter(range(len(accuracy)), accuracy)\n",
    "plt.title('Scattered Accuracy vs. Species', fontsize=24)\n",
    "plt.xlabel('Species across generations',fontsize=20)\n",
    "plt.ylabel('Test accuracy',fontsize=20)\n",
    "plt.tick_params(labelsize=20)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18, 12)\n",
    "plt.savefig('plot/accuracy_' + str(experiment) +'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and standard deviation of accuracies per generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABFUAAAQqCAYAAACGF0DfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIjFQUkVEREREREREJAb/D3EpViMuTGPyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f14c7309b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_generations = 20\n",
    "population_size = 10\n",
    "num_epochs = 10\n",
    "accuracy_per_gen = np.split(accuracy, num_generations)\n",
    "average_per_gen = []\n",
    "std_dev_per_gen = []\n",
    "for item in accuracy_per_gen:\n",
    "    average = np.mean(item)\n",
    "    std_dev = np.std(item)\n",
    "    average_per_gen.append(average)\n",
    "    std_dev_per_gen.append(std_dev)\n",
    "\n",
    "plt.figure(3)\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(range(1,num_generations+1), average_per_gen)\n",
    "plt.title('Average Accuracy vs. Generation', fontsize=24)\n",
    "plt.xlabel('Generation',fontsize=20)\n",
    "plt.ylabel('Average accuracy',fontsize=20)\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.xticks(np.arange(1, num_generations+1, 1))\n",
    "\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(1,num_generations+1), std_dev_per_gen)\n",
    "plt.title('Standard Deviation of Accuracy vs. Generation', fontsize=24)\n",
    "plt.xlabel('Generation',fontsize=20)\n",
    "plt.ylabel('Standard deviation',fontsize=20)\n",
    "plt.tick_params(labelsize=20)\n",
    "plt.xticks(np.arange(1, num_generations+1, 1))\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18, 18)\n",
    "plt.savefig('plot/mean_std_' + str(experiment) +'.png')\n",
    "plt.show()\n",
    "#print(average_per_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy scattered based on network structures across generations\n",
    "Note that a network has at least 1 convolutional layer and 1 dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the accuracy data points based on the network structure\n",
    "conv3den2=[]   # Network with 3(maximum) convolutional layers and 2(maximum) dense layers\n",
    "conv3den1=[]   # Network with 3(maximum) convolutional layers and 1 dense layers\n",
    "conv2den2=[]   # Network with 2 convolutional layers and 2(maximum) dense layers\n",
    "conv2den1=[]   # Network with 2 convolutional layers and 1 dense layers\n",
    "conv1den2=[]   # Network with 1 convolutional layers and 1 dense layers\n",
    "conv1den1=[]   # Network with 1 convolutional layers and 1 dense layers\n",
    "\n",
    "gen = 1\n",
    "pop = 0\n",
    "for row in data:\n",
    "    pop += 1\n",
    "    if pop > population_size:\n",
    "        gen += 1\n",
    "        pop = 1\n",
    "    if row[0] + row[6] + row[12] == 3:\n",
    "        if row[18] == 1:\n",
    "            conv3den2.append((gen,row[-1]))\n",
    "        else:\n",
    "            conv3den1.append((gen,row[-1]))\n",
    "    elif row[0] + row[6] + row[12] == 2:\n",
    "        if row[18] == 1:\n",
    "            conv2den2.append((gen,row[-1]))\n",
    "        else:\n",
    "            conv2den1.append((gen,row[-1]))\n",
    "    else:\n",
    "        if row[18] == 1:\n",
    "            conv1den2.append((gen,row[-1]))\n",
    "        else:\n",
    "            conv1den1.append((gen,row[-1]))\n",
    "print(len(conv3den2))\n",
    "print(len(conv3den1))\n",
    "print(len(conv2den2))\n",
    "print(len(conv2den1))\n",
    "print(len(conv1den2))\n",
    "print(len(conv1den1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(4)\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y']\n",
    "x1,y1 = zip(*conv3den2)\n",
    "x2,y2 = zip(*conv3den1)\n",
    "x3,y3 = zip(*conv2den2)\n",
    "x4,y4 = zip(*conv2den1)\n",
    "x5,y5 = zip(*conv1den2)\n",
    "x6,y6 = zip(*conv1den1)\n",
    "\n",
    "\n",
    "\n",
    "f, (ax, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "ax.scatter(x1,y1,color=colors[0])\n",
    "ax.scatter(x2,y2,color=colors[1])\n",
    "ax.scatter(x3,y3,color=colors[2])\n",
    "ax.scatter(x4,y4,color=colors[3])\n",
    "ax.scatter(x5,y5,color=colors[4])\n",
    "ax.scatter(x6,y6,color=colors[5])\n",
    "\n",
    "conv3_den2 = ax2.scatter(x1,y1,color=colors[0])\n",
    "conv3_den1 = ax2.scatter(x2,y2,color=colors[1])\n",
    "conv2_den2 = ax2.scatter(x3,y3,color=colors[2])\n",
    "conv2_den1 = ax2.scatter(x4,y4,color=colors[3])\n",
    "conv1_den2 = ax2.scatter(x5,y5,color=colors[4])\n",
    "conv1_den1 = ax2.scatter(x6,y6,color=colors[5])\n",
    "\n",
    "ax.set_ylim(.94, 1.)  # outliers only\n",
    "ax2.set_ylim(0.09, .12)  # most of the data\n",
    "\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax.xaxis.tick_top()\n",
    "ax.tick_params(labeltop='off')  # don't put tick labels at the top\n",
    "ax2.xaxis.tick_bottom()\n",
    "f.subplots_adjust(hspace=0.15)\n",
    "\n",
    "ax2.legend((conv3_den2, conv3_den1, conv2_den2, conv2_den1, conv1_den2, conv1_den1),\n",
    "           ('conv3_den2', 'conv3_den1', 'conv2_den2', 'conv2_den1', 'conv1_den2', 'conv1_den1'),\n",
    "           scatterpoints=1,\n",
    "           loc='lower right',\n",
    "           ncol=1,\n",
    "           fontsize=24)\n",
    "\n",
    "ax.set_title('Scattered Accuracy based on Network Structure vs. Generation', fontsize=24)\n",
    "ax2.set_xlabel('Generation',fontsize=20)\n",
    "ax.set_ylabel('Test accuracy',fontsize=20)\n",
    "ax2.set_ylabel('Test accuracy',fontsize=20)\n",
    "\n",
    "ax.tick_params(labelsize=20)\n",
    "ax2.tick_params(labelsize=20)\n",
    "\n",
    "ax2.xaxis.set_ticks(np.arange(1, num_generations+1, 1))\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18, 20)\n",
    "plt.savefig('plot/accuracy_structure_' + str(experiment) +'.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(5)\n",
    "\n",
    "conv3den2_avg = np.mean(y1)\n",
    "conv3den2_std = np.std(y1)\n",
    "conv3den1_avg = np.mean(y2)\n",
    "conv3den1_std = np.std(y2)\n",
    "conv2den2_avg = np.mean(y3)\n",
    "conv2den2_std = np.std(y3)\n",
    "conv2den1_avg = np.mean(y4)\n",
    "conv2den1_std = np.std(y4)\n",
    "conv1den2_avg = np.mean(y5)\n",
    "conv1den2_std = np.std(y5)\n",
    "conv1den1_avg = np.mean(y6)\n",
    "conv1den1_std = np.std(y6)\n",
    "\n",
    "plt.scatter(conv3den2_std,conv3den2_avg,color=colors[0])\n",
    "plt.scatter(conv3den1_std,conv3den1_avg,color=colors[1])\n",
    "plt.scatter(conv2den2_std,conv2den2_avg,color=colors[2])\n",
    "plt.scatter(conv2den1_std,conv2den1_avg,color=colors[3])\n",
    "plt.scatter(conv1den2_std,conv1den2_avg,color=colors[4])\n",
    "plt.scatter(conv1den1_std,conv1den1_avg,color=colors[5])\n",
    "\n",
    "plt.legend(('conv3_den2', 'conv3_den1', 'conv2_den2', 'conv2_den1', 'conv1_den2', 'conv1_den1'),\n",
    "           scatterpoints=1,\n",
    "           loc='lower left',\n",
    "           ncol=1,\n",
    "           fontsize=24)\n",
    "\n",
    "plt.tick_params(labelsize=20)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 10)\n",
    "plt.savefig('plot/mean_std_structure_' + str(experiment) +'.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
